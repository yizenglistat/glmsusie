% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model.R
\name{glmsusie}
\alias{glmsusie}
\title{Generalized Linear Models with Confidence Sets (glmsusie)}
\usage{
glmsusie(
  X,
  y,
  L = 10L,
  family = gaussian(),
  coverage = 0.95,
  cor_threshold = 0.5,
  standardize = TRUE,
  decompose = TRUE,
  shrinkage = TRUE,
  tol = 0.05,
  lambda = 0,
  tau = 1e-05,
  ties = c("efron", "breslow"),
  max_iter = 500L,
  seed = NULL
)
}
\arguments{
\item{X}{Numeric matrix of predictors (n × p). If a vector is provided, it will
be converted to a single-column matrix.}

\item{y}{Response variable:
\itemize{
\item For GLMs: numeric vector of length n
\item For Cox models: numeric matrix with 2 columns (time, status) and n rows
}}

\item{L}{Integer specifying the number of components to fit (default: 10).
Will be truncated to min(10, ncol(X)) if necessary.}

\item{family}{A family object specifying the model type (e.g., \code{gaussian()},
\code{binomial()}, \code{poisson()}, \code{Gamma()}) or \code{list(family="cox")}
for Cox regression.}

\item{coverage}{Numeric in \eqn{[0,1]} specifying the target coverage probability
for confidence sets (default: 0.95).}

\item{cor_threshold}{Numeric in \eqn{[0,1]} specifying the minimum absolute correlation
required for variables to be grouped in the same confidence set (default: 0.5).}

\item{standardize}{Logical indicating whether to center and scale predictors
before fitting (default: TRUE).}

\item{decompose}{Logical indicating whether to decompose theta in fitting (default: TRUE).}

\item{shrinkage}{Logical indicating whether to shrinkage parameters using pvals (default: TRUE).}

\item{tol}{Numeric specifying convergence tolerance for the expected log-likelihood
between iterations (default: 5e-2).}

\item{lambda}{Numeric penalty weight for the truncated-L1 penalty (default: 0.0).
If 0, no penalization is applied.}

\item{tau}{Numeric truncation parameter for the truncated-L1 penalty (default: 1e-5).
Controls the transition from L1 to L0 regularization.}

\item{ties}{Character string specifying the method for handling tied event times
in Cox regression: "efron" (default) or "breslow".}

\item{max_iter}{Integer specifying maximum number of coordinate ascent iterations
(default: 100).}

\item{seed}{Integer seed for reproducibility (default: NULL).}
}
\value{
A list with class "glmsusie" containing:
\describe{
\item{call}{The matched call}
\item{X}{The model matrix}
\item{y}{The response vector/matrix}
\item{family}{The family object used}
\item{theta}{p × L matrix of estimated coefficients for each single effect}
\item{intercept}{Estimated intercept (NULL for Cox regression)}
\item{pmp}{p × L matrix of posterior model probabilities}
\item{loglik}{p × L matrix of log-likelihoods}
\item{bic}{p × L matrix of BIC values}
\item{bic_diff}{p × L matrix of BIC differences from null model}
\item{evidence}{p × L matrix of evidence}
\item{bf}{p × L matrix of Bayes factors}
\item{marginal}{Vector of marginal inclusion probabilities for each predictor}
\item{kept}{Logical vector indicating which effects were retained}
\item{cs}{List of confidence sets based on posterior probabilities}
\item{niter}{Number of iterations performed}
\item{max_iter}{Number of maximum iterations}
\item{elapsed}{Elapsed computation time in seconds}
}
}
\description{
Fits a sparse Likelihood-based Additive Single-Effect Regression (LASER) model
using iteratively blockwise coordinate ascent. The model represents the coefficient
vector as a sum of sparse "single effects" and produces confidence sets for variable
selection based on posterior model probabilities.
}
\details{
The LASER model decomposes the coefficient vector into a sum of L sparse components.
At each iteration, the algorithm cyclically updates one component while holding
the others fixed. For each component, it fits a univariate model for each predictor,
computes model probabilities (via BIC), and updates coefficients as probability-weighted
averages. The approach extends traditional GLMs by providing Bayesian-inspired confidence
sets for variable selection.

Supported model families include:
\itemize{
\item Gaussian linear regression
\item Binomial logistic regression
\item Poisson regression
\item Gamma regression
\item Other GLM family regression
\item Cox proportional hazards regression
}
}
\examples{
\dontrun{
# Gaussian linear regression example
set.seed(42)
n <- 100
p <- 50
X <- matrix(rnorm(n*p), n, p)
colnames(X) <- paste0("X", 1:p)
true_beta <- c(rep(1, 5), rep(0, p-5))
y <- X \%*\% true_beta + rnorm(n)

# Fit model with 3 components
fit <- glmsusie(X, y, L = 3, family = gaussian())

# Examine results
summary(fit)
plot(fit)

# Extract coefficients
coef(fit)
coef(fit, intercept = TRUE)

# Cox regression example
X <- matrix(rnorm(100*10), 100, 10)
colnames(X) <- paste0("X", 1:10)
times <- rexp(100, rate = exp(0.5 * X[,1] + 0.5 * X[,2]))
status <- rbinom(100, 1, 0.7)
y_cox <- cbind(times, status)

fit_cox <- glmsusie(X, y_cox, L = 2, family = list(family = "cox"))
summary(fit_cox)
}

}
\seealso{
\code{\link{summary.glmsusie}} for summarizing model results,
\code{\link{coef.glmsusie}} for extracting coefficients,
\code{\link{plot.glmsusie}} for plotting results
}
