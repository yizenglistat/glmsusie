[{"path":"https://yizenglistat.github.io/glmsusie/articles/cox.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Cox Regression with Correlated Predictors","text":"glmsusie package implements generalized sum single effects (gSuSiE) model, represents overall effect sum small number single-effect components. approach extends variable selection various regression models including Cox proportional hazards regression survival analysis. vignette, demonstrate gSuSiE’s performance survival outcomes highly correlated predictors: Simulate block-wise correlation structure 100 predictors Apply gSuSiE perform variable selection via glmsusie() Cox regression Visualize coefficient estimates, posterior inclusion probabilities (PIPs), credible sets (CSs) Evaluate predictive performance survival analysis","code":""},{"path":"https://yizenglistat.github.io/glmsusie/articles/cox.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"Cox Regression with Correlated Predictors","text":"generate n=1000 observations p=100 predictors block-wise correlation. Every 10 consecutive variables highly correlated (\\rho=0.95) within block, blocks independent. 4 variables nonzero effects hazard, located different correlation blocks.","code":"set.seed(42) n <- 1000     # sample size p <- 100      # number of predictors L <- 10       # number of single-effect components block_size <- 10 n_blocks <- p / block_size rho <- 0.95    # within-block correlation  # Create block-wise correlation matrix Sigma <- matrix(0, p, p) for (b in 1:n_blocks) {   block_idx <- ((b-1)*block_size + 1):(b*block_size)   # Within-block correlation matrix   block_corr <- matrix(rho, block_size, block_size)   diag(block_corr) <- 1   Sigma[block_idx, block_idx] <- block_corr }  # Generate correlated predictors X <- MASS::mvrnorm(n, mu = rep(0, p), Sigma = Sigma)  # True sparse coefficients (one per block, spread across different blocks) theta_true <- rep(0, p) theta_true[c(3, 18, 47, 82)] <- c(1, -1, 1, -1)  # Generate survival data library(survival) linear_pred <- drop(X %*% theta_true) hazard_ratio <- exp(linear_pred)  # Generate survival times from exponential distribution lambda_baseline <- 0.1 survival_times <- rexp(n, rate = lambda_baseline * hazard_ratio)  # Generate censoring times (administrative censoring) censor_times <- runif(n, min = 5, max = 15)  # Observed times and event indicators observed_times <- pmin(survival_times, censor_times) event_indicator <- as.numeric(survival_times <= censor_times)  # Create survival object y <- Surv(observed_times, event_indicator)  cat(\"True nonzero coefficients at positions:\", which(theta_true != 0), \"\\n\") ## True nonzero coefficients at positions: 3 18 47 82 cat(\"True coefficient values:\", theta_true[theta_true != 0], \"\\n\") ## True coefficient values: 1 -1 1 -1 cat(\"Event rate:\", mean(event_indicator), \"\\n\") ## Event rate: 0.608 cat(\"Median follow-up time:\", median(observed_times), \"\\n\") ## Median follow-up time: 4.682838"},{"path":"https://yizenglistat.github.io/glmsusie/articles/cox.html","id":"fit-gsusie-model","dir":"Articles","previous_headings":"","what":"Fit gSuSiE model","title":"Cox Regression with Correlated Predictors","text":"allow L=10 single effects use Cox family survival regression. method robust larger L values minimal overfitting risk.","code":"# Load glmsusie library library(glmsusie)  # Model fitting fit <- glmsusie(   X      = X,   y      = y,   L      = L,   family = cox() )  summary(fit) ##  ## Call: ## glmsusie(X = X, y = y, L = L, family = cox()) ##  ## Family: cox  ##  ## Coefficients: (sorted by PIP) ##         Estimate    PIP ## X47  0.901898999 1.0000 ## X82 -0.852089479 1.0000 ## X18 -0.874196084 1.0000 ## X3   0.810845532 1.0000 ## X7   0.064899968 0.3493 ## X9   0.053064353 0.2864 ## X2   0.019897998 0.1139 ## X5   0.008076569 0.0493 ## X1   0.007753359 0.0479 ## X4   0.007636828 0.0464 ## ... (90 more coefficients not shown) ##  ## 95% Confidence Sets: ##                          Set Coverage ## cs1                     {82}   1.0000 ## cs2                      {3}   1.0000 ## cs3                     {47}   1.0000 ## cs4                     {18}   1.0000 ## cs5 {1, 2, 3, 4, 5, 6, 7, 9}   0.9517 ##  ## Model converged after 3 iterations. ## Computation time: 90.57 seconds."},{"path":[]},{"path":"https://yizenglistat.github.io/glmsusie/articles/cox.html","id":"coefficient-estimates","dir":"Articles","previous_headings":"Results","what":"Coefficient estimates","title":"Cox Regression with Correlated Predictors","text":"method successfully identifies true signal locations despite high correlation within blocks:","code":"plot(fit, which = \"coefficients\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/cox.html","id":"posterior-inclusion-probabilities","dir":"Articles","previous_headings":"Results","what":"Posterior inclusion probabilities","title":"Cox Regression with Correlated Predictors","text":"Shows probability variable included single-effect component:","code":"plot(fit, which = \"probabilities\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/cox.html","id":"credible-sets","dir":"Articles","previous_headings":"Results","what":"95% credible sets","title":"Cox Regression with Correlated Predictors","text":"credible set contains variables least one likely active 95% confidence. Note method handles correlated variables within blocks:","code":"plot(fit, which = \"sets\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/cox.html","id":"credible-sets-summary","dir":"Articles","previous_headings":"Results","what":"Credible sets summary","title":"Cox Regression with Correlated Predictors","text":"","code":"# Summary of credible sets cs_sets <- fit$cs$sets if (length(cs_sets) > 0) {   cat(\"Number of credible sets:\", length(cs_sets), \"\\n\")   for (i in seq_along(cs_sets)) {     cat(\"CS\", i, \"contains variables:\", cs_sets[[i]], \"\\n\")   }      # Check coverage of true variables   true_vars <- which(theta_true != 0)   covered_vars <- intersect(unlist(cs_sets), true_vars)   cat(\"\\nTrue variables covered by credible sets:\", covered_vars, \"\\n\") } else {   cat(\"No credible sets identified\\n\") } ## Number of credible sets: 5  ## CS 1 contains variables: 82  ## CS 2 contains variables: 3  ## CS 3 contains variables: 47  ## CS 4 contains variables: 18  ## CS 5 contains variables: 1 2 3 4 5 6 7 9  ##  ## True variables covered by credible sets: 82 3 47 18"},{"path":"https://yizenglistat.github.io/glmsusie/articles/cox.html","id":"coefficient-comparison","dir":"Articles","previous_headings":"Results","what":"Coefficient comparison","title":"Cox Regression with Correlated Predictors","text":"Compare estimated coefficients true values:","code":"# Extract coefficients coef_est <- coef(fit) comparison <- data.frame(   Variable = 1:p,   True_Coef = theta_true,   Estimated_Coef = coef_est,   PIP = fit$pip )  # Show results for true active variables active_comparison <- comparison[theta_true != 0, ] print(active_comparison) ##     Variable True_Coef Estimated_Coef       PIP ## X3         3         1      0.8108455 0.9999920 ## X18       18        -1     -0.8741961 0.9999999 ## X47       47         1      0.9018990 1.0000000 ## X82       82        -1     -0.8520895 1.0000000"},{"path":"https://yizenglistat.github.io/glmsusie/articles/cox.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Cox Regression with Correlated Predictors","text":"example demonstrates gSuSiE effectively handles Cox proportional hazards regression highly correlated predictors. method identifies relevant variables even embedded within correlation blocks, providing point estimates uncertainty quantification credible sets. Cox family implementation successfully recovers sparse signal structure survival data properly handling censoring semi-parametric nature Cox model.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/articles/gaussian.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Gaussian Linear Regression with Correlated Predictors","text":"glmsusie package implements generalized sum single effects (gSuSiE) model, represents overall effect sum small number single-effect components. approach extends SuSiE method generalized linear models. vignette, demonstrate gSuSiE’s performance highly correlated predictors: Simulate block-wise correlation structure 100 predictors Apply gSuSiE perform variable selection via glmsusie() Visualize coefficient estimates, posterior inclusion probabilities (PIPs), credible sets (CSs) Compare performance SuSiE","code":""},{"path":"https://yizenglistat.github.io/glmsusie/articles/gaussian.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"Gaussian Linear Regression with Correlated Predictors","text":"generate n=5000 observations p=100 predictors block-wise correlation. Every 10 consecutive variables highly correlated (\\rho=0.98) within block, blocks independent. 4 variables nonzero effects, located different correlation blocks.","code":"set.seed(42) n <- 5000     # sample size p <- 100     # number of predictors L <- 10      # number of single-effect components block_size <- 10 n_blocks <- p / block_size rho <- 0.98   # within-block correlation  # Create block-wise correlation matrix Sigma <- matrix(0, p, p) for (b in 1:n_blocks) {   block_idx <- ((b-1)*block_size + 1):(b*block_size)   # Within-block correlation matrix   block_corr <- matrix(rho, block_size, block_size)   diag(block_corr) <- 1   Sigma[block_idx, block_idx] <- block_corr }  # Generate correlated predictors X <- MASS::mvrnorm(n, mu = rep(0, p), Sigma = Sigma)  # True sparse coefficients (one per block, spread across different blocks) theta_true <- rep(0, p) theta_true[c(3, 18, 47, 82)] <- c(1, -1, 1, -1)  # Generate response y <- drop(X %*% theta_true + rnorm(n, sd = 3))  cat(\"True nonzero coefficients at positions:\", which(theta_true != 0), \"\\n\") ## True nonzero coefficients at positions: 3 18 47 82 cat(\"True coefficient values:\", theta_true[theta_true != 0], \"\\n\") ## True coefficient values: 1 -1 1 -1"},{"path":"https://yizenglistat.github.io/glmsusie/articles/gaussian.html","id":"fit-gsusie-model","dir":"Articles","previous_headings":"","what":"Fit gSuSiE model","title":"Gaussian Linear Regression with Correlated Predictors","text":"allow L=10 single effects use default Gaussian family. method robust larger L values minimal overfitting risk.","code":"# Load glmsusie library library(glmsusie)  # Model fitting fit <- glmsusie(   X      = X,   y      = y,   L      = L,   family = gaussian() )  summary(fit) ##  ## Call: ## glmsusie(X = X, y = y, L = L, family = gaussian()) ##  ## Family: gaussian  ##  ## Coefficients: (sorted by PIP) ##        Estimate    PIP ## X18 -0.99143940 0.9936 ## X82 -1.04180572 0.9888 ## X3   0.91926763 0.9810 ## X47  0.43663754 0.6886 ## X45  0.23453415 0.4970 ## X50  0.08743698 0.2307 ## X49  0.04493075 0.1328 ## X44  0.04494264 0.1311 ## X41  0.02691908 0.0851 ## X43  0.01019643 0.0358 ## ... (90 more coefficients not shown) ##  ## 95% Confidence Sets: ##                                  Set Coverage ## cs1                             {82}   0.9888 ## cs2                              {3}   0.9810 ## cs3 {41, 42, 43, 44, 45, 47, 49, 50}   0.9762 ## cs4                 {44, 45, 47, 50}   0.9633 ## cs5                             {18}   0.9936 ##  ## Model converged after 3 iterations. ## Computation time: 14.44 seconds."},{"path":[]},{"path":"https://yizenglistat.github.io/glmsusie/articles/gaussian.html","id":"coefficient-estimates","dir":"Articles","previous_headings":"Results","what":"Coefficient estimates","title":"Gaussian Linear Regression with Correlated Predictors","text":"method successfully identifies true signal locations despite high correlation within blocks:","code":"plot(fit, which = \"coefficients\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/gaussian.html","id":"posterior-inclusion-probabilities","dir":"Articles","previous_headings":"Results","what":"Posterior inclusion probabilities","title":"Gaussian Linear Regression with Correlated Predictors","text":"Shows probability variable included single-effect component:","code":"plot(fit, which = \"probabilities\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/gaussian.html","id":"credible-sets","dir":"Articles","previous_headings":"Results","what":"95% credible sets","title":"Gaussian Linear Regression with Correlated Predictors","text":"credible set contains variables least one likely active 95% confidence. Note method handles correlated variables within blocks:","code":"plot(fit, which = \"sets\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/gaussian.html","id":"performance-evaluation","dir":"Articles","previous_headings":"Results","what":"Performance evaluation","title":"Gaussian Linear Regression with Correlated Predictors","text":"Compare predictive performance methods:","code":"# Prediction performance rmse_glmsusie <- sqrt(mean(residuals(fit)^2))  # Compare with SuSiE fit_susie <- susieR::susie(X, y, L = L) fitted_susie <- fitted(fit_susie) rmse_susie <- sqrt(mean((y - fitted_susie)^2))  performance <- data.frame(   Method = c(\"SuSiE\", \"gSuSiE\"),   RMSE = c(rmse_susie, rmse_glmsusie) )  print(performance) ##   Method     RMSE ## 1  SuSiE 3.008884 ## 2 gSuSiE 3.009010"},{"path":"https://yizenglistat.github.io/glmsusie/articles/gaussian.html","id":"susie-credible-sets-comparison","dir":"Articles","previous_headings":"Results","what":"SuSiE credible sets comparison","title":"Gaussian Linear Regression with Correlated Predictors","text":"Examine credible sets identified SuSiE:","code":"# SuSiE credible sets cat(\"SuSiE Credible Sets:\\n\") ## SuSiE Credible Sets: susie_sets <- fit_susie$sets$cs if (length(susie_sets) > 0) {   for (i in seq_along(susie_sets)) {     cs_vars <- susie_sets[[i]]     cs_pips <- fit_susie$pip[cs_vars]          # Format variables with their PIPs     var_pip_strings <- paste0(cs_vars, \" (PIP: \", round(cs_pips, 4), \")\")          cat(\"CS\", names(susie_sets)[i], \"contains variables:\",          paste(var_pip_strings, collapse = \", \"), \"\\n\")   } } else {   cat(\"No credible sets identified by SuSiE\\n\") } ## CS L1 contains variables: 82 (PIP: 0.9872)  ## CS L2 contains variables: 18 (PIP: 0.9934)  ## CS L4 contains variables: 3 (PIP: 0.9775)  ## CS L3 contains variables: 45 (PIP: 0.2959), 47 (PIP: 0.6635)"},{"path":"https://yizenglistat.github.io/glmsusie/articles/gaussian.html","id":"visualize-susie-credible-sets","dir":"Articles","previous_headings":"Results","what":"Visualize SuSiE credible sets","title":"Gaussian Linear Regression with Correlated Predictors","text":"","code":"# Create matrix for SuSiE credible sets visualization if (length(susie_sets) > 0) {   # Create probability matrix for credible sets   susie_cs_matrix <- matrix(0, nrow = length(susie_sets), ncol = p)      for (i in seq_along(susie_sets)) {     cs_vars <- susie_sets[[i]]     # Use PIPs as probabilities for variables in the credible set     susie_cs_matrix[i, cs_vars] <- fit_susie$pip[cs_vars]   }      # Plot SuSiE credible sets using our plotting function   plot_cs_matrix(susie_cs_matrix,                   row_labels = paste0(\"SuSiE CS_\", names(susie_sets)),                  alpha = 0.05) } else {   cat(\"No SuSiE credible sets to visualize\\n\") }"},{"path":"https://yizenglistat.github.io/glmsusie/articles/gaussian.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Gaussian Linear Regression with Correlated Predictors","text":"example demonstrates gSuSiE effectively handles highly correlated predictors. method identifies informative variables even embedded within correlation blocks, providing point estimates uncertainty quantification credible sets.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/articles/logit.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Logistic Regression with Correlated Predictors","text":"glmsusie package implements generalized sum single effects (gSuSiE) model, represents overall effect sum small number single-effect components. approach extends SuSiE method general regression models including logistic regression. vignette, demonstrate gSuSiE’s performance binary outcomes highly correlated predictors: Simulate block-wise correlation structure 100 predictors Apply gSuSiE perform variable selection via glmsusie() binomial family Visualize coefficient estimates, posterior inclusion probabilities (PIPs), credible sets (CSs) Evaluate predictive performance binary classification","code":""},{"path":"https://yizenglistat.github.io/glmsusie/articles/logit.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"Logistic Regression with Correlated Predictors","text":"generate n=2500 observations p=100 predictors block-wise correlation. Every 10 consecutive variables highly correlated (\\rho=0.95) within block, blocks independent. 4 variables nonzero effects, located different correlation blocks.","code":"set.seed(42) n <- 2500     # sample size p <- 100      # number of predictors L <- 10       # number of single-effect components block_size <- 10 n_blocks <- p / block_size rho <- 0.95    # within-block correlation  # Create block-wise correlation matrix Sigma <- matrix(0, p, p) for (b in 1:n_blocks) {   block_idx <- ((b-1)*block_size + 1):(b*block_size)   # Within-block correlation matrix   block_corr <- matrix(rho, block_size, block_size)   diag(block_corr) <- 1   Sigma[block_idx, block_idx] <- block_corr }  # Generate correlated predictors X <- MASS::mvrnorm(n, mu = rep(0, p), Sigma = Sigma)  # True sparse coefficients (one per block, spread across different blocks) theta_true <- rep(0, p) theta_true[c(3, 18, 47, 82)] <- c(1, -1, 1, -1)  # Generate binary response via logistic model linear_pred <- drop(-3 + X %*% theta_true) # with intercept prob <- plogis(linear_pred)  # inverse logit y <- rbinom(n, 1, prob)  cat(\"True nonzero coefficients at positions:\", which(theta_true != 0), \"\\n\") ## True nonzero coefficients at positions: 3 18 47 82 cat(\"True coefficient values:\", theta_true[theta_true != 0], \"\\n\") ## True coefficient values: 1 -1 1 -1 cat(\"Response proportion (positives):\", mean(y), \"\\n\") ## Response proportion (positives): 0.1328"},{"path":"https://yizenglistat.github.io/glmsusie/articles/logit.html","id":"fit-gsusie-model","dir":"Articles","previous_headings":"","what":"Fit gSuSiE model","title":"Logistic Regression with Correlated Predictors","text":"allow L=10 single effects use binomial family logistic regression. method robust larger L values minimal overfitting risk.","code":"# Load glmsusie library library(glmsusie)  # Model fitting fit <- glmsusie(   X      = X,   y      = y,   L      = L,   family = binomial() )  summary(fit) ##  ## Call: ## glmsusie(X = X, y = y, L = L, family = binomial()) ##  ## Family: binomial  ##  ## Coefficients: (sorted by PIP) ##        Estimate    PIP ## X82 -1.02522761 0.9979 ## X18 -0.98738766 0.9962 ## X3   0.90256709 0.9791 ## X47  0.51813756 0.7045 ## X42  0.16480081 0.3267 ## X44  0.07489590 0.1875 ## X45  0.05783056 0.1544 ## X41  0.04501620 0.1313 ## X43  0.02078277 0.0785 ## X50  0.01642584 0.0651 ## ... (90 more coefficients not shown) ##  ## 95% Confidence Sets: ##                  Set Coverage ## cs1             {82}   0.9979 ## cs2              {3}   0.9790 ## cs3 {42, 44, 45, 47}   0.9536 ## cs4             {18}   0.9962 ##  ## Model converged after 3 iterations. ## Computation time: 17.06 seconds."},{"path":[]},{"path":"https://yizenglistat.github.io/glmsusie/articles/logit.html","id":"coefficient-estimates","dir":"Articles","previous_headings":"Results","what":"Coefficient estimates","title":"Logistic Regression with Correlated Predictors","text":"method successfully identifies true signal locations despite high correlation within blocks:","code":"plot(fit, which = \"coefficients\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/logit.html","id":"posterior-inclusion-probabilities","dir":"Articles","previous_headings":"Results","what":"Posterior inclusion probabilities","title":"Logistic Regression with Correlated Predictors","text":"Shows probability variable included single-effect component:","code":"plot(fit, which = \"probabilities\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/logit.html","id":"credible-sets","dir":"Articles","previous_headings":"Results","what":"95% credible sets","title":"Logistic Regression with Correlated Predictors","text":"credible set contains variables least one likely active 95% confidence. Note method handles correlated variables within blocks:","code":"plot(fit, which = \"sets\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/logit.html","id":"credible-sets-summary","dir":"Articles","previous_headings":"Results","what":"Credible sets summary","title":"Logistic Regression with Correlated Predictors","text":"","code":"# Summary of credible sets cs_sets <- fit$cs$sets if (length(cs_sets) > 0) {   cat(\"Number of credible sets:\", length(cs_sets), \"\\n\")   for (i in seq_along(cs_sets)) {     cat(\"CS\", i, \"contains variables:\", cs_sets[[i]], \"\\n\")   }      # Check coverage of true variables   true_vars <- which(theta_true != 0)   covered_vars <- intersect(unlist(cs_sets), true_vars)   cat(\"\\nTrue variables covered by credible sets:\", covered_vars, \"\\n\") } else {   cat(\"No credible sets identified\\n\") } ## Number of credible sets: 4  ## CS 1 contains variables: 82  ## CS 2 contains variables: 3  ## CS 3 contains variables: 42 44 45 47  ## CS 4 contains variables: 18  ##  ## True variables covered by credible sets: 82 3 47 18"},{"path":"https://yizenglistat.github.io/glmsusie/articles/logit.html","id":"coefficient-comparison","dir":"Articles","previous_headings":"Results","what":"Coefficient comparison","title":"Logistic Regression with Correlated Predictors","text":"Compare estimated coefficients true values:","code":"# Extract coefficients coef_est <- coef(fit) comparison <- data.frame(   Variable = 1:p,   True_Coef = theta_true,   Estimated_Coef = coef_est,   PIP = fit$pip )  # Show results for true active variables active_comparison <- comparison[theta_true != 0, ] print(active_comparison) ##     Variable True_Coef Estimated_Coef       PIP ## X3         3         1      0.9025671 0.9790571 ## X18       18        -1     -0.9873877 0.9961945 ## X47       47         1      0.5181376 0.7044932 ## X82       82        -1     -1.0252276 0.9978847"},{"path":"https://yizenglistat.github.io/glmsusie/articles/logit.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Logistic Regression with Correlated Predictors","text":"example demonstrates gSuSiE effectively handles logistic regression highly correlated predictors. method identifies relevant variables even embedded within correlation blocks, providing point estimates uncertainty quantification credible sets. binomial family implementation successfully recovers sparse signal structure binary outcomes.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/articles/mwe.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"A Minimal Example","text":"glmsusie package implements generalized sum single effects (gSuSiE) model, represents overall effect sum small number single-effect components. vignette : Simulate high-dimensional sparse linear regression dataset Apply gSuSiE perform variable selection via glmsusie() Visualize coefficient estimates, posterior inclusion probabilities (PIPs), credible sets (CSs) . Evaluate predictive performance vs. SuSiE","code":""},{"path":"https://yizenglistat.github.io/glmsusie/articles/mwe.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"A Minimal Example","text":"generate sparse linear regression dataset n=1000 observations p=1000 predictors, 4 variables nonzero effects.","code":"set.seed(42) n <- 1000    # sample size p <- 1000    # number of predictors L <- 10      # number of single-effect components  # true sparse coefficients theta_true <- rep(0, p) theta_true[c(100, 200, 300, 400)] <- 1  # covariate matrix and response X <- matrix(rnorm(n * p), nrow = n, ncol = p) y <- drop(X %*% theta_true + rnorm(n))"},{"path":"https://yizenglistat.github.io/glmsusie/articles/mwe.html","id":"fit-the-laser-model","dir":"Articles","previous_headings":"","what":"Fit the LASER model","title":"A Minimal Example","text":"allow (L=10) single effects use default Gaussian family. Generally, method robust larger L values present minimal risk overfitting.","code":"# load glmsusie library library(glmsusie)  # model fitting fit <- glmsusie(   X              = X,   y              = y,   L              = L,   family         = gaussian() ) summary(fit) ##  ## Call: ## glmsusie(X = X, y = y, L = L, family = gaussian()) ##  ## Family: gaussian  ##  ## Coefficients: (sorted by PIP) ##       Estimate    PIP ## X300 1.0347174 1.0000 ## X400 0.9491801 1.0000 ## X100 0.9476146 1.0000 ## X200 0.9745533 0.9997 ## X1   0.0000000 0.0000 ## X2   0.0000000 0.0000 ## X3   0.0000000 0.0000 ## X4   0.0000000 0.0000 ## X5   0.0000000 0.0000 ## X6   0.0000000 0.0000 ## ... (990 more coefficients not shown) ##  ## 95% Confidence Sets: ##       Set Coverage ## cs1 {200}   0.9997 ## cs2 {100}   1.0000 ## cs3 {400}   1.0000 ## cs4 {300}   1.0000 ##  ## Model converged after 4 iterations. ## Computation time: 28.51 seconds."},{"path":[]},{"path":"https://yizenglistat.github.io/glmsusie/articles/mwe.html","id":"coefficient-estimates","dir":"Articles","previous_headings":"Results","what":"Coefficient estimates","title":"A Minimal Example","text":"recover four peaks true locations","code":"# plot coefficients plot(fit, which=\"coefficients\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/mwe.html","id":"estimated-inclusion-probability","dir":"Articles","previous_headings":"Results","what":"Estimated inclusion probability","title":"A Minimal Example","text":"Shows inclusion probability variable included single-effect component:","code":"# plot coefficients plot(fit, which=\"probabilities\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/mwe.html","id":"estimated-95-confidence-sets","dir":"Articles","previous_headings":"Results","what":"Estimated 95% confidence sets","title":"A Minimal Example","text":"confidence set (CS) contains small group variables least one likely active, 95\\% confidence.","code":"# plot coefficients plot(fit, which=\"sets\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/mwe.html","id":"performance-evalution","dir":"Articles","previous_headings":"Results","what":"Performance evalution","title":"A Minimal Example","text":"","code":"rmse_glmsusie <- sqrt(mean(residuals(fit)^2))  # compare with SuSiE fitted_susie  <- fitted(susieR::susie(X, y, L)) rmse_susie    <- sqrt(mean((y - fitted_susie)^2))  data.frame(   Method = c(\"susie\", \"glmsusie\"),   RMSE   = c(rmse_susie, rmse_glmsusie) ) ##     Method      RMSE ## 1    susie 0.9728844 ## 2 glmsusie 0.9609528"},{"path":"https://yizenglistat.github.io/glmsusie/articles/poisson.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Poisson Regression with Correlated Predictors","text":"glmsusie package implements generalized sum single effects (gSuSiE) model, represents overall effect sum small number single-effect components. approach extends variable selection various regression models including Poisson regression count data analysis. vignette, demonstrate gSuSiE’s performance count outcomes highly correlated predictors: Simulate block-wise correlation structure 100 predictors Apply gSuSiE perform variable selection via glmsusie() Poisson family Visualize coefficient estimates, posterior inclusion probabilities (PIPs), credible sets (CSs) Evaluate predictive performance count data regression","code":""},{"path":"https://yizenglistat.github.io/glmsusie/articles/poisson.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"Poisson Regression with Correlated Predictors","text":"generate n=1000 observations p=100 predictors block-wise correlation. Every 10 consecutive variables highly correlated (\\rho=0.95) within block, blocks independent. 4 variables nonzero effects log rate, located different correlation blocks.","code":"set.seed(42) n <- 1000     # sample size p <- 100      # number of predictors L <- 10       # number of single-effect components block_size <- 10 n_blocks <- p / block_size rho <- 0.95   # within-block correlation  # Create block-wise correlation matrix Sigma <- matrix(0, p, p) for (b in 1:n_blocks) {   block_idx <- ((b-1)*block_size + 1):(b*block_size)   # Within-block correlation matrix   block_corr <- matrix(rho, block_size, block_size)   diag(block_corr) <- 1   Sigma[block_idx, block_idx] <- block_corr }  # Generate correlated predictors X <- MASS::mvrnorm(n, mu = rep(0, p), Sigma = Sigma)  # True sparse coefficients (one per block, spread across different blocks) theta_true <- rep(0, p) theta_true[c(3, 18, 47, 82)] <- c(1, -1, 1, -1)  # Generate count response via Poisson model linear_pred <- drop(1.5 + X %*% theta_true)  # with intercept for reasonable counts lambda <- exp(linear_pred)  # log link y <- rpois(n, lambda)  cat(\"True nonzero coefficients at positions:\", which(theta_true != 0), \"\\n\") ## True nonzero coefficients at positions: 3 18 47 82 cat(\"True coefficient values:\", theta_true[theta_true != 0], \"\\n\") ## True coefficient values: 1 -1 1 -1 cat(\"Response summary:\\n\") ## Response summary: print(summary(y)) ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  ##    0.00    1.00    6.00   33.45   21.00 1971.00 cat(\"Mean count:\", mean(y), \"\\n\") ## Mean count: 33.449 cat(\"Variance:\", var(y), \"\\n\") ## Variance: 13133.63"},{"path":"https://yizenglistat.github.io/glmsusie/articles/poisson.html","id":"fit-gsusie-model","dir":"Articles","previous_headings":"","what":"Fit gSuSiE model","title":"Poisson Regression with Correlated Predictors","text":"allow L=10 single effects use Poisson family count regression. method robust larger L values minimal overfitting risk.","code":"# Load glmsusie library library(glmsusie)  # Model fitting fit <- glmsusie(   X      = X,   y      = y,   L      = L,   family = poisson() )  summary(fit) ##  ## Call: ## glmsusie(X = X, y = y, L = L, family = poisson()) ##  ## Family: poisson  ##  ## Coefficients: (sorted by PIP) ##         Estimate    PIP ## X3   1.008708486 1.0000 ## X18 -1.028419072 1.0000 ## X47  1.021851638 1.0000 ## X82 -1.011947072 1.0000 ## X12  0.003517262 0.1322 ## X19  0.003322508 0.1157 ## X13  0.002367051 0.0937 ## X20  0.002205109 0.0817 ## X14  0.002145315 0.0802 ## X11  0.001302258 0.0512 ## ... (90 more coefficients not shown) ##  ## 95% Confidence Sets: ##      Set Coverage ## cs1 {82}        1 ## cs2  {3}        1 ## cs3 {47}        1 ## cs4 {18}        1 ##  ## Model converged after 4 iterations. ## Computation time: 21.37 seconds."},{"path":[]},{"path":"https://yizenglistat.github.io/glmsusie/articles/poisson.html","id":"coefficient-estimates","dir":"Articles","previous_headings":"Results","what":"Coefficient estimates","title":"Poisson Regression with Correlated Predictors","text":"method successfully identifies true signal locations despite high correlation within blocks:","code":"plot(fit, which = \"coefficients\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/poisson.html","id":"posterior-inclusion-probabilities","dir":"Articles","previous_headings":"Results","what":"Posterior inclusion probabilities","title":"Poisson Regression with Correlated Predictors","text":"Shows probability variable included single-effect component:","code":"plot(fit, which = \"probabilities\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/poisson.html","id":"credible-sets","dir":"Articles","previous_headings":"Results","what":"95% credible sets","title":"Poisson Regression with Correlated Predictors","text":"credible set contains variables least one likely active 95% confidence. Note method handles correlated variables within blocks:","code":"plot(fit, which = \"sets\")"},{"path":"https://yizenglistat.github.io/glmsusie/articles/poisson.html","id":"credible-sets-summary","dir":"Articles","previous_headings":"Results","what":"Credible sets summary","title":"Poisson Regression with Correlated Predictors","text":"","code":"# Summary of credible sets cs_sets <- fit$cs$sets if (length(cs_sets) > 0) {   cat(\"Number of credible sets:\", length(cs_sets), \"\\n\")   for (i in seq_along(cs_sets)) {     cat(\"CS\", i, \"contains variables:\", cs_sets[[i]], \"\\n\")   }      # Check coverage of true variables   true_vars <- which(theta_true != 0)   covered_vars <- intersect(unlist(cs_sets), true_vars)   cat(\"\\nTrue variables covered by credible sets:\", covered_vars, \"\\n\")   cat(\"Coverage rate:\", length(covered_vars), \"/\", length(true_vars), \"\\n\") } else {   cat(\"No credible sets identified\\n\") } ## Number of credible sets: 4  ## CS 1 contains variables: 82  ## CS 2 contains variables: 3  ## CS 3 contains variables: 47  ## CS 4 contains variables: 18  ##  ## True variables covered by credible sets: 82 3 47 18  ## Coverage rate: 4 / 4"},{"path":"https://yizenglistat.github.io/glmsusie/articles/poisson.html","id":"coefficient-comparison","dir":"Articles","previous_headings":"Results","what":"Coefficient comparison","title":"Poisson Regression with Correlated Predictors","text":"Compare estimated coefficients true values:","code":"# Extract coefficients coef_est <- coef(fit) comparison <- data.frame(   Variable = 1:p,   True_Coef = theta_true,   Estimated_Coef = coef_est,   PIP = fit$pip )  # Show results for true active variables active_comparison <- comparison[theta_true != 0, ] print(active_comparison) ##     Variable True_Coef Estimated_Coef PIP ## X3         3         1       1.008708   1 ## X18       18        -1      -1.028419   1 ## X47       47         1       1.021852   1 ## X82       82        -1      -1.011947   1"},{"path":"https://yizenglistat.github.io/glmsusie/articles/poisson.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Poisson Regression with Correlated Predictors","text":"example demonstrates gSuSiE effectively handles Poisson regression highly correlated predictors. method identifies relevant variables even embedded within correlation blocks, providing point estimates uncertainty quantification credible sets. Poisson family implementation successfully recovers sparse signal structure count data properly handling log-linear relationship predictors rate parameter.","code":""},{"path":[]},{"path":"https://yizenglistat.github.io/glmsusie/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Yizeng Li. Author, maintainer. Wei Pan. Author.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Li Y, Pan W (2025). glmsusie: Generalized Linear Models Confident Sets. R package version 0.1.0, https://github.com/yizenglistat/glmsusie.","code":"@Manual{,   title = {glmsusie: Generalized Linear Models with Confident Sets},   author = {Yizeng Li and Wei Pan},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/yizenglistat/glmsusie}, }"},{"path":"https://yizenglistat.github.io/glmsusie/index.html","id":"about","dir":"","previous_headings":"","what":"About","title":"Generalized Linear Models with Confident Sets","text":"glmsusie package implements generalized Sum Single Effects (gSuSiE) model, likelihood-based extension Bayesian SuSiE framework variable selection generalized linear survival (Cox) regression models. gSuSiE designed settings highly correlated predictors sparse true signals, traditional penalized regression methods often struggle. core, gSuSiE decomposes regression effects additive “single-effect” components, enabling stable variable selection interpretable uncertainty quantification credible sets (CSs) — groups correlated variables collectively high probability containing least one true effect. Beyond credible sets posterior inclusion probabilities (PIPs), gSuSiE also provides standard errors, p-values, 2BIC statistics additional diagnostic measures, offering Bayesian frequentist perspectives variable importance. Developed Yizeng Li Wei Pan, Division Biostatistics Health data Science, University Minnesota Twin Cities.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick start","title":"Generalized Linear Models with Confident Sets","text":"can install released version glmsusie CRAN: Alternatively, install latest development version glmsusie Github: See brief illustraton glmsusie. documentation examples please visit https://github.com/yizenglistat/glmsusie.","code":"install.packages(\"glmsusie\") # install.packages(\"remotes\") remotes::install_github(\"yizenglistat/glmsusie\")"},{"path":"https://yizenglistat.github.io/glmsusie/reference/AIC.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract AIC from a glmsusie Object — AIC.glmsusie","title":"Extract AIC from a glmsusie Object — AIC.glmsusie","text":"Returns Akaike Information Criterion (AIC) glmsusie model.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/AIC.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract AIC from a glmsusie Object — AIC.glmsusie","text":"","code":"# S3 method for class 'glmsusie' AIC(object, ..., k = 2)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/AIC.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract AIC from a glmsusie Object — AIC.glmsusie","text":"object fitted model object class \"glmsusie\". ... Additional arguments (used). k Numeric, penalty per parameter used; default 2.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/AIC.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract AIC from a glmsusie Object — AIC.glmsusie","text":"AIC value.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/BIC.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract BIC from a glmsusie Object — BIC.glmsusie","title":"Extract BIC from a glmsusie Object — BIC.glmsusie","text":"Returns Bayesian Information Criterion (BIC) glmsusie model.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/BIC.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract BIC from a glmsusie Object — BIC.glmsusie","text":"","code":"# S3 method for class 'glmsusie' BIC(object, ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/BIC.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract BIC from a glmsusie Object — BIC.glmsusie","text":"object fitted model object class \"glmsusie\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/BIC.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract BIC from a glmsusie Object — BIC.glmsusie","text":"BIC value.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/additive_effect_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Likelihood-based Additive Single-Effect Regression (LASER) Model — additive_effect_fit","title":"Fit Likelihood-based Additive Single-Effect Regression (LASER) Model — additive_effect_fit","text":"Fits LASER model, representing coefficient vector sum L sparse \"single effects.\"  iteration, cyclically applies single_effect_fit update one effect holding others fixed, updates intercept (dispersion, applicable), convergence max_iter reached.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/additive_effect_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Likelihood-based Additive Single-Effect Regression (LASER) Model — additive_effect_fit","text":"X Numeric matrix (n × p) predictors. y Response: GLMs: numeric vector length n. Cox: numeric matrix 2 columns (time, status) n rows. L Integer; number single effects include (set min(10, L)). family stats::family object (e.g. gaussian(), binomial(), poisson()) Cox family list family = \"cox\". standardize Logical: TRUE, center scale predictor column fitting (default: TRUE). ties Character: ties method Cox partial likelihood (\"efron\" \"breslow\", default: \"efron\"). lambda Numeric penalty weight; ≤ 0, defaults \\(\\sqrt{2\\log(n)/n}\\) (default: 0.0). tau Numeric truncation parameter; ≤ 0, defaults 0.5 (default: 0.5). decompose Logical: TRUE, decompose theta fitting (default: TRUE). shrinkage Logical: TRUE, shrinkage parameters fitting (default: TRUE). alpha level significance tol Numeric; convergence tolerance change expected log-likelihood (default: 5e-2). max_iter Integer; maximum number coordinate-ascent iterations (default: 100).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/additive_effect_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Likelihood-based Additive Single-Effect Regression (LASER) Model — additive_effect_fit","text":"list components: niter Number iterations performed. loglik p × L matrix univariate log-likelihoods. expect_loglik Vector length niter giving expected log-likelihood iteration. final_loglik Expected log-likelihood convergence. intercept Estimated intercept term. dispersion Estimated dispersion parameter (Gaussian/Gamma). theta p × L matrix fitted single-effect coefficients. pval_intercept p × L matrix p-values fitted single-effect intercepts pval_theta p × L matrix p-values fitted single-effect coefficients. pmp p × L matrix posterior model probabilities. bic p × L matrix BIC values. bic_diff p × L matrix BIC differences null. bf p × L matrix Bayes factors. expect_variance Length-L vector PMP-weighted variances. elapsed_time Numeric; total computation time seconds.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/additive_effect_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Likelihood-based Additive Single-Effect Regression (LASER) Model — additive_effect_fit","text":"","code":"if (FALSE) { # \\dontrun{ # Gaussian example with 5 effects X <- matrix(rnorm(100*20), 100, 20) y <- rnorm(100) res <- additive_effect_fit(X, y, L = 5, family = gaussian())  # Cox regression example times  <- rexp(100) status <- rbinom(100, 1, 0.5) y_cox  <- cbind(times, status) res_cox <- additive_effect_fit(X, y_cox, L = 3,                                family = list(family = \"cox\"),                                ties = \"breslow\") } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/coef.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Model Coefficients from a glmsusie Object — coef.glmsusie","title":"Extract Model Coefficients from a glmsusie Object — coef.glmsusie","text":"Extracts coefficients glmsusie model fit summing coefficients across single effects predictor.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/coef.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Model Coefficients from a glmsusie Object — coef.glmsusie","text":"","code":"# S3 method for class 'glmsusie' coef(object, intercept = FALSE, ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/coef.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Model Coefficients from a glmsusie Object — coef.glmsusie","text":"object fitted model object class \"glmsusie\". intercept Logical; TRUE, include intercept term first element returned vector. Default FALSE. ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/coef.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Model Coefficients from a glmsusie Object — coef.glmsusie","text":"numeric vector coefficients, names corresponding column names design matrix. intercept = TRUE, first element named \"(Intercept)\".","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_fisher.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine p-values using Fisher's Method — combine_fisher","title":"Combine p-values using Fisher's Method — combine_fisher","text":"Aggregates vector p-values using Fisher's method, tests union null hypothesis component tests null. method powerful multiple weak signals present across independent weakly correlated tests.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_fisher.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine p-values using Fisher's Method — combine_fisher","text":"","code":"combine_fisher(pvals)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_fisher.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine p-values using Fisher's Method — combine_fisher","text":"pvals numeric vector p-values (typically predictor across models effects).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_fisher.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine p-values using Fisher's Method — combine_fisher","text":"scalar: Fisher-combined p-value.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_fisher.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Combine p-values using Fisher's Method — combine_fisher","text":"test statistic \\(T = -2 \\sum \\log(p_i)\\), follows chi-squared distribution \\(2k\\) degrees freedom null, \\(k\\) number p-values.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_fisher.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine p-values using Fisher's Method — combine_fisher","text":"","code":"if (FALSE) { # \\dontrun{ p <- c(0.01, 0.2, 0.04) combine_fisher(p) } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_simes.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine p-values using Simes' Method — combine_simes","title":"Combine p-values using Simes' Method — combine_simes","text":"Aggregates vector p-values using Simes' method, controls family-wise error rate union null hypothesis. particularly useful testing whether least one several related tests shows significant effect.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_simes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine p-values using Simes' Method — combine_simes","text":"","code":"combine_simes(pvals)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_simes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine p-values using Simes' Method — combine_simes","text":"pvals numeric vector p-values (e.g., L single-effect models one predictor).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_simes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine p-values using Simes' Method — combine_simes","text":"scalar: Simes-combined p-value.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_simes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Combine p-values using Simes' Method — combine_simes","text":"Simes p-value computed : $$\\min_{=1}^L \\frac{L \\cdot p_{()}}{}$$, \\(p_{()}\\) ordered p-values.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/combine_simes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine p-values using Simes' Method — combine_simes","text":"","code":"if (FALSE) { # \\dontrun{ p <- c(0.01, 0.2, 0.04) combine_simes(p) } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/confidence_set.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","title":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","text":"latent effect (column) posterior model probability matrix pmp, select smallest set variables whose cumulative probability reaches least coverage.  Optionally filter sets whose minimum absolute pairwise correlation (Rmat) cor_threshold, remove duplicates.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/confidence_set.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","text":"","code":"confidence_set(pmp, kept, coverage = 0.95, Rmat = NULL, cor_threshold = 0.5)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/confidence_set.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","text":"pmp Numeric matrix dimension \\(p \\times L\\), column sums 1 contains posterior inclusion probabilities variable effect. kept Logical vector length \\(L\\), indicating effects (columns) process. coverage Numeric scalar [0,1], target cumulative probability confidence set. Defaults 0.95. Rmat Optional \\(p \\times p\\) numeric correlation matrix predictors. supplied, set whose minimum -diagonal absolute correlation cor_threshold discarded.  Defaults NULL. cor_threshold Numeric scalar [0,1], minimum absolute correlation allowed within set pass correlation filter.  Defaults 0.5.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/confidence_set.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","text":"list components: sets named list integer vectors.  element cs1, cs2, … confidence set variable indices achieves target coverage.  sets survive filters, sets NULL. claimed Numeric vector actual cumulative probabilities (\"claimed coverage\") returned set.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/confidence_set.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","text":"","code":"# Simple two-effect example pmp <- matrix(c(0.6, 0.3, 0.1,                 0.2, 0.5, 0.3),               nrow = 3, byrow = FALSE) kept <- c(TRUE, TRUE) cs <- confidence_set(pmp, kept)  # With a correlation filter Rmat <- cor(matrix(rnorm(9), nrow = 3)) cs2 <- confidence_set(pmp, kept, coverage = 0.8, Rmat = Rmat, cor_threshold = 0.2)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Cox Proportional Hazards ","title":"Cox Proportional Hazards ","text":"Creates family object univariate Cox regression, compatible GLM‐style interfaces.  log link supported, yielding usual Cox partial‐likelihood formulation.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cox Proportional Hazards ","text":"","code":"cox(link = \"log\")"},{"path":"https://yizenglistat.github.io/glmsusie/reference/cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cox Proportional Hazards ","text":"link Character string; link function Cox model.  \"log\" supported (default).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cox Proportional Hazards ","text":"family object (list class \"family\") containing: family Always \"cox\". link Link name, \"log\". linkfun Function transforming mu eta. linkinv Inverse link, mapping eta mu. mu.eta Derivative linkinv. variance Variance function (returns 1). dev.resids Deviance residuals (zeros). aic AIC placeholder (returns -2). validmu, valideta Validation functions (always TRUE). dispersion Always 1.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/cox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cox Proportional Hazards ","text":"\"family\" object provides minimal set functions required use IRLS‐based routines log-likelihood calculations: linkfun linkinv implement log link. mu.eta provides derivative inverse link. variance, dev.resids, aic placeholders (used Cox needed compatibility).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/cox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cox Proportional Hazards ","text":"","code":"# Create the Cox family object fam <- cox(link = \"log\") stopifnot(fam$family == \"cox\") # Check that linkinv(exp(eta)) == exp(eta) eta <- c(0, 1, -1) all.equal(fam$linkinv(eta), exp(eta)) #> [1] TRUE"},{"path":"https://yizenglistat.github.io/glmsusie/reference/decompose_theta.html","id":null,"dir":"Reference","previous_headings":"","what":"Decompose Row Sums of a Theta Matrix into Single-Effect Components — decompose_theta","title":"Decompose Row Sums of a Theta Matrix into Single-Effect Components — decompose_theta","text":"Given \\(p \\times L\\) matrix theta, function redistributes row sums new matrix shape row's total effect placed single column (using round-robin assignment). operation useful decomposing combined effect vector sparse single-effect columns (e.g., spike--slab regression additive effect models).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/decompose_theta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decompose Row Sums of a Theta Matrix into Single-Effect Components — decompose_theta","text":"theta numeric matrix shape p × L. L Integer. Number columns output matrix.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/decompose_theta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decompose Row Sums of a Theta Matrix into Single-Effect Components — decompose_theta","text":"numeric matrix shape p × L, row sum matches corresponding row sum theta, row one nonzero entry.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/decompose_theta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decompose Row Sums of a Theta Matrix into Single-Effect Components — decompose_theta","text":"","code":"if (FALSE) { # \\dontrun{ theta <- matrix(rnorm(12), nrow = 6, ncol = 2) theta_new <- decompose_theta(theta, L = 2) all.equal(rowSums(theta), rowSums(theta_new))  # Should be TRUE } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/deviance.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Deviance for a glmsusie Object — deviance.glmsusie","title":"Calculate Deviance for a glmsusie Object — deviance.glmsusie","text":"Returns deviance glmsusie model.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/deviance.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Deviance for a glmsusie Object — deviance.glmsusie","text":"","code":"# S3 method for class 'glmsusie' deviance(object, ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/deviance.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Deviance for a glmsusie Object — deviance.glmsusie","text":"object fitted model object class \"glmsusie\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/deviance.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Deviance for a glmsusie Object — deviance.glmsusie","text":"Deviance value.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/dispersion.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Dispersion Parameter from a glmsusie Object — dispersion.glmsusie","title":"Extract Dispersion Parameter from a glmsusie Object — dispersion.glmsusie","text":"Returns estimated dispersion parameter glmsusie model.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/dispersion.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Dispersion Parameter from a glmsusie Object — dispersion.glmsusie","text":"","code":"dispersion.glmsusie(object, ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/dispersion.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Dispersion Parameter from a glmsusie Object — dispersion.glmsusie","text":"object fitted model object class \"glmsusie\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/dispersion.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Dispersion Parameter from a glmsusie Object — dispersion.glmsusie","text":"Dispersion parameter value.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/fitted.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Fitted Values from a glmsusie Object — fitted.glmsusie","title":"Extract Fitted Values from a glmsusie Object — fitted.glmsusie","text":"Returns fitted values glmsusie model object.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/fitted.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Fitted Values from a glmsusie Object — fitted.glmsusie","text":"","code":"# S3 method for class 'glmsusie' fitted(object, ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/fitted.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Fitted Values from a glmsusie Object — fitted.glmsusie","text":"object fitted model object class \"glmsusie\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/fitted.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Fitted Values from a glmsusie Object — fitted.glmsusie","text":"vector fitted values scale response variable.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/generate.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Synthetic Data for Benchmark Simulations — generate","title":"Generate Synthetic Data for Benchmark Simulations — generate","text":"Creates design matrix X controlled correlation structure simulates response y according specified family.  Supports Gaussian, Binomial, Poisson, Gamma GLMs, Cox survival data exponential baseline hazard.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/generate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Synthetic Data for Benchmark Simulations — generate","text":"","code":"generate(   n = 600,   theta = c(1, 0),   intercept = 0,   settings = c(\"ex1\", \"ex2\", \"ex3\"),   rho = 0.9,   dispersion = 1,   family = gaussian(),   censoring_rate = 0.3,   baseline_hazard = 1 )"},{"path":"https://yizenglistat.github.io/glmsusie/reference/generate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Synthetic Data for Benchmark Simulations — generate","text":"n Integer; number observations (default: 600). theta Numeric vector true coefficients (length p). intercept Numeric; true intercept term (default: 0). settings Character; correlation pattern: \"ex1\": p variables equally correlated. \"ex2\": first 5×5 block correlated, others independent. \"ex3\": two p/2 × p/2 blocks correlated. Default: c(\"ex1\",\"ex2\",\"ex3\"). rho Numeric [0,1]; within-block correlation (default: 0.9). dispersion Numeric; dispersion Gaussian/Gamma (default: 1). family family object (e.g. gaussian(), binomial(), poisson(), Gamma()) string \"cox\" survival data (default: gaussian()). censoring_rate Numeric [0,1]; fraction censored Cox models (default: 0.3). baseline_hazard Numeric function; constant hazard rate Cox, hazard function provided (default: 1).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/generate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Synthetic Data for Benchmark Simulations — generate","text":"list components: X n × p design matrix specified correlation. y Response: Numeric vector length n (GLMs). n × 2 matrix (time, status) (Cox). eta Linear predictor intercept + X %*% theta.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/generate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Synthetic Data for Benchmark Simulations — generate","text":"","code":"if (FALSE) { # \\dontrun{ # Gaussian data, p = 2 dat1 <- generate(n = 100, theta = c(1, 0), settings = \"ex1\",                  family = gaussian(), dispersion = 2)  # Binomial data with probit link dat2 <- generate(n = 200, theta = c(0.5, -0.5),                  family = binomial(link = \"probit\"),                  settings = \"ex2\", rho = 0.7)  # Cox survival data dat3 <- generate(n = 150, theta = c(1, 1, 0),                  settings = \"ex3\", family = \"cox\",                  censoring_rate = 0.2, baseline_hazard = 0.05) } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/glmsusie-package.html","id":null,"dir":"Reference","previous_headings":"","what":"glmsusie: Generalized Linear Models with Confident Sets — glmsusie-package","title":"glmsusie: Generalized Linear Models with Confident Sets — glmsusie-package","text":"Implements likelihood-based additive single-effect regression (LASER) via blockwise coordinate ascent algorithm, providing confident sets variable selection uncertainty quantification. Features include robust variable selection high multicollinearity, confident sets capture posterior uncertainty variable inclusion, flexible modeling linear, generalized linear, Cox regression, high performance via C++ backend, configurable parameters number effects, coverage, convergence tolerance.","code":""},{"path":[]},{"path":"https://yizenglistat.github.io/glmsusie/reference/glmsusie-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"glmsusie: Generalized Linear Models with Confident Sets — glmsusie-package","text":"Maintainer: Yizeng Li yizenglistat@gmail.com Authors: Wei Pan panxx014@umn.edu","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Linear Models with Confidence Sets (glmsusie) — glmsusie","title":"Generalized Linear Models with Confidence Sets (glmsusie) — glmsusie","text":"Fits sparse Likelihood-based Additive Single-Effect Regression (LASER) model using iteratively blockwise coordinate ascent. model represents coefficient vector sum sparse \"single effects\" produces confidence sets variable selection based posterior model probabilities.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Linear Models with Confidence Sets (glmsusie) — glmsusie","text":"","code":"glmsusie(   X,   y,   L = 10L,   family = gaussian(),   coverage = 0.95,   cor_threshold = 0.5,   standardize = TRUE,   decompose = TRUE,   shrinkage = TRUE,   tol = 0.05,   lambda = 0,   tau = 1e-05,   ties = c(\"efron\", \"breslow\"),   max_iter = 500L,   seed = NULL )"},{"path":"https://yizenglistat.github.io/glmsusie/reference/glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Linear Models with Confidence Sets (glmsusie) — glmsusie","text":"X Numeric matrix predictors (n × p). vector provided, converted single-column matrix. y Response variable: GLMs: numeric vector length n Cox models: numeric matrix 2 columns (time, status) n rows L Integer specifying number components fit (default: 10). truncated min(10, ncol(X)) necessary. family family object specifying model type (e.g., gaussian(), binomial(), poisson(), Gamma()) list(family=\"cox\") Cox regression. coverage Numeric \\([0,1]\\) specifying target coverage probability confidence sets (default: 0.95). cor_threshold Numeric \\([0,1]\\) specifying minimum absolute correlation required variables grouped confidence set (default: 0.5). standardize Logical indicating whether center scale predictors fitting (default: TRUE). decompose Logical indicating whether decompose theta fitting (default: TRUE). shrinkage Logical indicating whether shrinkage parameters using pvals (default: TRUE). tol Numeric specifying convergence tolerance expected log-likelihood iterations (default: 5e-2). lambda Numeric penalty weight truncated-L1 penalty (default: 0.0). 0, penalization applied. tau Numeric truncation parameter truncated-L1 penalty (default: 1e-5). Controls transition L1 L0 regularization. ties Character string specifying method handling tied event times Cox regression: \"efron\" (default) \"breslow\". max_iter Integer specifying maximum number coordinate ascent iterations (default: 100). seed Integer seed reproducibility (default: NULL).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Linear Models with Confidence Sets (glmsusie) — glmsusie","text":"list class \"glmsusie\" containing: call matched call X model matrix y response vector/matrix family family object used theta p × L matrix estimated coefficients single effect intercept Estimated intercept (NULL Cox regression) pmp p × L matrix posterior model probabilities loglik p × L matrix log-likelihoods bic p × L matrix BIC values bic_diff p × L matrix BIC differences null model evidence p × L matrix evidence bf p × L matrix Bayes factors marginal Vector marginal inclusion probabilities predictor kept Logical vector indicating effects retained cs List confidence sets based posterior probabilities niter Number iterations performed max_iter Number maximum iterations elapsed Elapsed computation time seconds","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/glmsusie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Linear Models with Confidence Sets (glmsusie) — glmsusie","text":"LASER model decomposes coefficient vector sum L sparse components. iteration, algorithm cyclically updates one component holding others fixed. component, fits univariate model predictor, computes model probabilities (via BIC), updates coefficients probability-weighted averages. approach extends traditional GLMs providing Bayesian-inspired confidence sets variable selection. Supported model families include: Gaussian linear regression Binomial logistic regression Poisson regression Gamma regression GLM family regression Cox proportional hazards regression","code":""},{"path":[]},{"path":"https://yizenglistat.github.io/glmsusie/reference/glmsusie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Linear Models with Confidence Sets (glmsusie) — glmsusie","text":"","code":"if (FALSE) { # \\dontrun{ # Gaussian linear regression example set.seed(42) n <- 100 p <- 50 X <- matrix(rnorm(n*p), n, p) colnames(X) <- paste0(\"X\", 1:p) true_beta <- c(rep(1, 5), rep(0, p-5)) y <- X %*% true_beta + rnorm(n)  # Fit model with 3 components fit <- glmsusie(X, y, L = 3, family = gaussian())  # Examine results summary(fit) plot(fit)  # Extract coefficients coef(fit) coef(fit, intercept = TRUE)  # Cox regression example X <- matrix(rnorm(100*10), 100, 10) colnames(X) <- paste0(\"X\", 1:10) times <- rexp(100, rate = exp(0.5 * X[,1] + 0.5 * X[,2])) status <- rbinom(100, 1, 0.7) y_cox <- cbind(times, status)  fit_cox <- glmsusie(X, y_cox, L = 2, family = list(family = \"cox\")) summary(fit_cox) } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/is_covered.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","title":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","text":"Determines true active variables included least one provided confidence sets. Returns TRUE every element true_active appears union sets, FALSE otherwise.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/is_covered.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","text":"","code":"is_covered(confidence_sets, true_active)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/is_covered.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","text":"confidence_sets list integer vectors, representing confidence set selected variable indices. single vector provided, coerced list length one. true_active Integer vector true active variable indices.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/is_covered.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","text":"Logical scalar. TRUE elements true_active contained union confidence_sets, FALSE otherwise.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/is_covered.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","text":"","code":"# Single set, true actives 1 and 3 are both covered is_covered(confidence_sets = c(1, 3, 5), true_active = c(1, 3)) #> [1] TRUE  # Multiple sets, true active 2 appears in one of them sets <- list(cs1 = c(1,4), cs2 = c(2,5), cs3 = c(3)) is_covered(confidence_sets = sets, true_active = c(2,3)) #> [1] TRUE  # Not covered if any true active is missing is_covered(confidence_sets = list(c(1,4)), true_active = c(1,2)) #> [1] FALSE"},{"path":"https://yizenglistat.github.io/glmsusie/reference/iskept.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Columns with Significant and Non-Diffuse Credible Sets — iskept","title":"Select Columns with Significant and Non-Diffuse Credible Sets — iskept","text":"function identifies columns probability matrix : (1) statistically significant based column-wise p-value aggregation method (e.g., Simes), (2) concentrated, sense credible set formed PIPs include variables. column significant, fallback selects column whose p-values non-uniform.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/iskept.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Columns with Significant and Non-Diffuse Credible Sets — iskept","text":"","code":"iskept(pmp, pval, alpha = 0.05)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/iskept.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Columns with Significant and Non-Diffuse Credible Sets — iskept","text":"pmp numeric matrix posterior inclusion probabilities (PIPs), dimension p × L. pval numeric matrix p-values, dimension p × L, column corresponds single effect. alpha Significance threshold p-value aggregation credible set construction (default = 0.05).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/iskept.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Columns with Significant and Non-Diffuse Credible Sets — iskept","text":"logical vector length L indicating selected columns: TRUE column retained (significant non-diffuse), FALSE otherwise. Column names preserved present. least one column always selected.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/iskept.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select Columns with Significant and Non-Diffuse Credible Sets — iskept","text":"Columns first assessed using combine_simes combine p-values across rows. Among significant columns (p-value < alpha), evaluated forming credible set posterior inclusion probabilities (PIPs). credible set consists variables ranked PIP included cumulative sum reaches least 1 - alpha. credible set includes variables, column excluded diffuse. prevents keeping effects concentrate signal subset variables. columns remain filtering, function selects column non-uniform p-value distribution (based variance mean).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/iskept.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Select Columns with Significant and Non-Diffuse Credible Sets — iskept","text":"Assumes column pval pmp corresponds single-effect model.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/logLik.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Log-Likelihood from a glmsusie Object — logLik.glmsusie","title":"Extract Log-Likelihood from a glmsusie Object — logLik.glmsusie","text":"Returns log-likelihood glmsusie model object.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/logLik.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Log-Likelihood from a glmsusie Object — logLik.glmsusie","text":"","code":"# S3 method for class 'glmsusie' logLik(object, ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/logLik.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Log-Likelihood from a glmsusie Object — logLik.glmsusie","text":"object fitted model object class \"glmsusie\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/logLik.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Log-Likelihood from a glmsusie Object — logLik.glmsusie","text":"Log-likelihood value.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/plot.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a glmsusie Model Object — plot.glmsusie","title":"Plot a glmsusie Model Object — plot.glmsusie","text":"Produces various plots visualizing glmsusie model results.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/plot.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a glmsusie Model Object — plot.glmsusie","text":"","code":"# S3 method for class 'glmsusie' plot(x, which = c(\"coefficients\", \"probabilities\", \"sets\"), n_top = 20, ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/plot.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a glmsusie Model Object — plot.glmsusie","text":"x glmsusie object. Integer character string specifying plot create: 1 \"coefficients\": Plot coefficient estimates 2 \"probabilities\": Plot inclusion probabilities 3 \"sets\": Visualization confidence sets n_top Integer specifying many top coefficients display. ... Additional arguments passed plotting functions.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/plot.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a glmsusie Model Object — plot.glmsusie","text":"ggplot2 object.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/plot_cs_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot inclusion probabilities for a set of ","title":"Plot inclusion probabilities for a set of ","text":"Plot inclusion probabilities set \"confidence sets\"","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/plot_cs_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot inclusion probabilities for a set of ","text":"","code":"plot_cs_matrix(   prob_mat,   row_labels = paste0(\"CS\", seq_len(nrow(prob_mat))),   var_labels = seq_len(ncol(prob_mat)),   low_col = \"white\",   high_col = \"black\",   drop_zero = TRUE )"},{"path":"https://yizenglistat.github.io/glmsusie/reference/plot_cs_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot inclusion probabilities for a set of ","text":"prob_mat Numeric matrix (r × p) probabilities (row sums 1). row_labels Optional character vector length r. Default paste0(\"CS\", 1:r). var_labels Optional character numeric vector length p. Default 1:p. low_col Colour P≈0. Default \"white\". high_col Colour P≈1. Default \"black\". drop_zero Logical; TRUE, drop zero-probability entries (default: TRUE).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/plot_cs_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot inclusion probabilities for a set of ","text":"ggplot2 object showing crosses size ∝ P colour ∝ P.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/predict.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Predictions from a glmsusie Object — predict.glmsusie","title":"Model Predictions from a glmsusie Object — predict.glmsusie","text":"Produces predictions glmsusie model new data original training data.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/predict.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Predictions from a glmsusie Object — predict.glmsusie","text":"","code":"# S3 method for class 'glmsusie' predict(object, newdata = NULL, type = c(\"link\", \"response\", \"terms\"), ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/predict.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Predictions from a glmsusie Object — predict.glmsusie","text":"object fitted model object class \"glmsusie\". newdata optional data frame matrix look variables predict. omitted, fitted values returned. type Character string specifying type prediction: \"link\": predictions scale linear predictors \"response\": predictions scale response \"terms\": contributions individual terms ... Additional arguments passed family's link function.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/predict.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Predictions from a glmsusie Object — predict.glmsusie","text":"Vector matrix predictions, depending type.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/print.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a glmsusie Model Object — print.glmsusie","title":"Print a glmsusie Model Object — print.glmsusie","text":"Print glmsusie Model Object","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/print.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a glmsusie Model Object — print.glmsusie","text":"","code":"# S3 method for class 'glmsusie' print(x, ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/print.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a glmsusie Model Object — print.glmsusie","text":"x glmsusie object. ... Additional arguments passed print.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/print.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a glmsusie Model Object — print.glmsusie","text":"object invisibly.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/print.summary.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a glmsusie Model Summary — print.summary.glmsusie","title":"Print a glmsusie Model Summary — print.summary.glmsusie","text":"Print glmsusie Model Summary","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/print.summary.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a glmsusie Model Summary — print.summary.glmsusie","text":"","code":"# S3 method for class 'summary.glmsusie' print(x, digits = max(3, getOption(\"digits\") - 3), max_sets = 5, ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/print.summary.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a glmsusie Model Summary — print.summary.glmsusie","text":"x summary.glmsusie object created summary.glmsusie(). digits Number significant digits use printing. max_sets Maximum number confidence sets display (default: 5). ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/print.summary.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a glmsusie Model Summary — print.summary.glmsusie","text":"summary object invisibly.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/residuals.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Residuals from a glmsusie Object — residuals.glmsusie","title":"Extract Residuals from a glmsusie Object — residuals.glmsusie","text":"Extracts residuals glmsusie model fit.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/residuals.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Residuals from a glmsusie Object — residuals.glmsusie","text":"","code":"# S3 method for class 'glmsusie' residuals(object, type = c(\"deviance\", \"pearson\", \"response\", \"working\"), ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/residuals.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Residuals from a glmsusie Object — residuals.glmsusie","text":"object fitted model object class \"glmsusie\". type Character string indicating type residuals returned: \"deviance\": deviance residuals \"pearson\": Pearson residuals \"response\": response residuals (observed - fitted) \"working\": working residuals ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/residuals.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Residuals from a glmsusie Object — residuals.glmsusie","text":"numeric vector residuals.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/single_effect_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Single‐Effect Fit for GLM or Cox with Optional Truncated‐L1 Penalty — single_effect_fit","title":"Compute Single‐Effect Fit for GLM or Cox with Optional Truncated‐L1 Penalty — single_effect_fit","text":"Applies single‐effect model column predictor matrix using either GLM (via IRLS + truncated‐L1) Cox partial likelihood (via penalized IRLS).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/single_effect_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Single‐Effect Fit for GLM or Cox with Optional Truncated‐L1 Penalty — single_effect_fit","text":"X Numeric matrix (n × p) predictors. column fit separately. y Response: GLMs: numeric vector length n. Cox: numeric matrix 2 columns (time, status) n rows. family stats::family object (e.g. gaussian(), binomial(), poisson()) Cox family list family = \"cox\". offset Numeric scalar vector (length n) giving linear predictor offset (default: 0). standardize Logical: TRUE, center scale predictor column fitting (default: TRUE). shrinkage Logical: TRUE, shrinkage parameters fitting (default: TRUE). ties Character: ties method Cox partial likelihood (\"efron\" \"breslow\", default: \"efron\"). lambda Numeric penalty weight; ≤ 0, defaults \\(\\sqrt{2\\log(n)/n}\\) (default: 0.0). tau Numeric truncation parameter; ≤ 0, defaults 1.0 (default: 1.0). alpha level significance","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/single_effect_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Single‐Effect Fit for GLM or Cox with Optional Truncated‐L1 Penalty — single_effect_fit","text":"list length p, element list components: loglik Unpenalized log‐likelihood fitted coefficient. bic Bayesian Information Criterion: \\(-2*logLik + 2\\log(n)\\). bic_diff BIC difference null model. bf Bayes factor. pmp Posterior model probability. intercept Estimated intercept predictor. theta Estimated coefficient predictor. pval_intercept P-value estimated intercept predictor. pval_theta P-value estimated coefficient predictor. expect_intercept Expected value intercept model averaging. expect_theta Expected value coefficient model averaging. expect_variance Expected variance model averaging.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/single_effect_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Single‐Effect Fit for GLM or Cox with Optional Truncated‐L1 Penalty — single_effect_fit","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) n <- 80; p <- 3 X <- matrix(rnorm(n*p), n, p) # Gaussian example y_gauss <- X[,1] * 1.2 + rnorm(n) res_glm <- single_effect_fit(X, y_gauss, family = gaussian())  # Cox example times <- rexp(n, rate = exp(0.5 * X[,2])) status <- rbinom(n, 1, 0.7) y_cox <- cbind(time=times, status=status) res_cox <- single_effect_fit(X, y_cox, family = list(family=\"cox\")) } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/summarize_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize Coefficient Estimates Across Simulations — summarize_coef","title":"Summarize Coefficient Estimates Across Simulations — summarize_coef","text":"Given matrix simulated coefficient estimates true coefficient vector, compute per‐variable summary statistics: empirical mean standard deviation estimates, alongside true value.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/summarize_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize Coefficient Estimates Across Simulations — summarize_coef","text":"","code":"summarize_coef(sims_coef, true_theta, decimal = 2)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/summarize_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize Coefficient Estimates Across Simulations — summarize_coef","text":"sims_coef Numeric matrix dimension \\(p \\times n_{\\text{sim}}\\), row corresponds one predictor column simulation replicate. true_theta Numeric vector length \\(p\\), containing true coefficient values predictor. decimal Nonnegative integer.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/summarize_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize Coefficient Estimates Across Simulations — summarize_coef","text":"data.frame columns: true true coefficient values, true_theta. mean Row‐wise mean sims_coef, average estimated coefficient. ssd Row‐wise standard deviation sims_coef, empirical sampling variability.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/summarize_coef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize Coefficient Estimates Across Simulations — summarize_coef","text":"","code":"# Suppose we ran 100 simulations for 3 predictors set.seed(42) true_theta <- c(1.5, 0, -2) sims_coef  <- matrix(rnorm(3 * 100, mean = rep(true_theta, each = 100), sd = 0.3),                      nrow = 3, byrow = TRUE) summarize_coef(sims_coef, true_theta) #>   true  mean  ssd #> 1  1.5  1.51 0.31 #> 2  0.0 -0.03 0.27 #> 3 -2.0 -2.00 0.31"},{"path":"https://yizenglistat.github.io/glmsusie/reference/summarize_cs.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize Multi‐Set Confidence Regions Across Simulations — summarize_cs","title":"Summarize Multi‐Set Confidence Regions Across Simulations — summarize_cs","text":"Given list simulation results run may return multiple confidence sets (e.g. cs1, cs2, …), function enumerates distinct patterns sets, counts often occurs, computes fraction simulations, tests whether union sets pattern covers true active variables.  Within pattern, individual sets ordered first size (smallest first), lexicographically indices.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/summarize_cs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize Multi‐Set Confidence Regions Across Simulations — summarize_cs","text":"","code":"summarize_cs(cs_list, true_active, decimal = 2)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/summarize_cs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize Multi‐Set Confidence Regions Across Simulations — summarize_cs","text":"cs_list List length n_sims. element either: R list (e.g. list(cs1=..., cs2=..., …)) integer vectors, NULL empty list, meaning confidence sets returned. inner integer vector holds indices single confidence set. true_active Integer vector true active variable indices. decimal Nonnegative integer.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/summarize_cs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize Multi‐Set Confidence Regions Across Simulations — summarize_cs","text":"data.frame columns: set Character: unique simulation pattern rendered comma‐separated set literals, e.g.\\  \"{1,4}, {2,3}\".  empty pattern shown \"{}\". count Integer: number simulations produced exactly pattern sets. percent Numeric: count divided n_sims. cover Logical: TRUE union sets pattern contains every element true_active. Rows sorted descending order count.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/summary.glmsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize a glmsusie Model Fit — summary.glmsusie","title":"Summarize a glmsusie Model Fit — summary.glmsusie","text":"Produces summary glmsusie model fit, including coefficients, confidence sets, model fit statistics.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/summary.glmsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize a glmsusie Model Fit — summary.glmsusie","text":"","code":"# S3 method for class 'glmsusie' summary(object, ...)"},{"path":"https://yizenglistat.github.io/glmsusie/reference/summary.glmsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize a glmsusie Model Fit — summary.glmsusie","text":"object fitted model object class \"glmsusie\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/summary.glmsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize a glmsusie Model Fit — summary.glmsusie","text":"list class \"summary.glmsusie\" containing various summary statistics.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Univariate Fit with Optional Truncated‐L1 Penalty — univariate_fit","title":"Compute Univariate Fit with Optional Truncated‐L1 Penalty — univariate_fit","text":"Fits single‐covariate model (GLM Cox) optional standardization truncated‐L1 penalty coefficient.  GLMs uses IRLS capped‐L1 update; Cox uses penalized IRLS partial likelihood.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Univariate Fit with Optional Truncated‐L1 Penalty — univariate_fit","text":"x Numeric vector covariate values (length n); scalar expands zeros. y Response: GLMs: numeric vector length n. Cox: numeric matrix 2 columns (time, status) n rows. family stats::family object (e.g. gaussian(), binomial(), poisson()) Cox family list family = \"cox\". offset Numeric scalar vector (length n) giving linear predictor offset (default: 0). standardize Logical: TRUE, center scale x fitting (default: TRUE). ties Character: ties method Cox partial likelihood (\"efron\" \"breslow\", default: \"efron\"). lambda Numeric penalty weight; NULL ≤ 0, defaults \\(\\sqrt{2\\log(n)/n}\\). tau Numeric truncation parameter; NULL ≤ 0, defaults 0.5.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Univariate Fit with Optional Truncated‐L1 Penalty — univariate_fit","text":"list elements: intercept Estimated intercept (undoing standardization). theta Estimated coefficient (undoing standardization). loglik Unpenalized log-likelihood estimated theta. bic Bayesian Information Criterion: \\(-2*loglik + 2\\log(n)\\).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Univariate Fit with Optional Truncated‐L1 Penalty — univariate_fit","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(101) n <- 50 x <- rnorm(n) # Gaussian GLM y_gauss <- 1.5*x + rnorm(n) res1 <- univariate_fit(x, y_gauss, family = gaussian(), offset = 0)  # Cox example times  <- rexp(n, rate = exp(0.7*x)) status <- rbinom(n, 1, 0.6) y_cox  <- cbind(time=times, status=status) res2 <- univariate_fit(x, y_cox, family = list(family=\"cox\")) } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","title":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","text":"Fits univariate Cox proportional hazards model maximizing partial log-likelihood using Iteratively Reweighted Least Squares (IRLS) approach. Supports Breslow Efron approximations handling ties.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","text":"x Numeric vector length n: covariate values. y Numeric matrix shape n × 2, : y[,1] observed time y[,2] event indicator (1 = event, 0 = censored) offset Numeric scalar vector length n. Optional offset linear predictor. ties Character string specifying method handle ties: \"breslow\" (default) \"efron\". lambda Numeric penalty weight; ≤ 0, defaults \\(\\sqrt{2\\log(n)/n}\\) (default: 0.0). tau Numeric truncation parameter; ≤ 0, defaults 0.5 (default: 0.5). max_iter Integer: maximum number IRLS iterations. Default 25. tol Numeric: convergence tolerance parameter change. Default 1e-8.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","text":"numeric scalar representing estimated regression coefficient theta.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_cox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","text":"function starts initial coefficient value 0 updates slope estimate using Newton-Raphson iterations convergence reaching maximum number iterations. linear predictor lp = offset + theta * x. score function observed information used update estimate.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_cox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","text":"","code":"if (FALSE) { # \\dontrun{ x <- c(1, 2, 3, 4) y <- matrix(c(4,1, 1,1, 3,0, 2,1), ncol = 2, byrow = TRUE) univariate_irls_cox(x, y, offset = 0, ties = \"efron\", max_iter = 50, tol = 1e-6) } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Generalized Linear Model Estimate for Univariate Predictor with Intercept — univariate_irls_glm","title":"Compute Generalized Linear Model Estimate for Univariate Predictor with Intercept — univariate_irls_glm","text":"Fits GLM intercept single predictor using iteratively reweighted least squares (IRLS). Implements model: $$g(E[y]) = \\beta_0 + \\beta_1 x + \\text{offset}$$ \\(g\\) link function determined selected family.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Generalized Linear Model Estimate for Univariate Predictor with Intercept — univariate_irls_glm","text":"x Numeric vector covariates (length n). y Numeric response vector (length n). family stats::family object (e.g. gaussian(), binomial(), poisson()). offset Numeric scalar vector (length n) giving linear predictor offset. max_iter Integer. Maximum number IRLS iterations. tol Numeric convergence tolerance parameters.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Generalized Linear Model Estimate for Univariate Predictor with Intercept — univariate_irls_glm","text":"list components: intercept Numeric scalar: estimated intercept \\(\\hat\\beta_0\\). theta Numeric scalar: estimated coefficient \\(\\hat\\beta_1\\).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_glm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Generalized Linear Model Estimate for Univariate Predictor with Intercept — univariate_irls_glm","text":"function implements standard IRLS algorithm GLMs, optimized univariate predictor case intercept. provides identical results R's glm(y ~ x, family=family) computationally efficient single-predictor case. Numerical stability measures implemented handling extreme values, including special cases Poisson regression fallback methods matrix solution standard solve fails.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Generalized Linear Model Estimate for Univariate Predictor with Intercept — univariate_irls_glm","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(42) n <- 100 x <- rnorm(n)  # Gaussian example y_gaussian <- 2 + 0.5*x + rnorm(n) result <- univariate_irls_glm(x, y_gaussian, gaussian(), offset=numeric(0)) print(result)  # Poisson example eta <- 1 + 0.5*x y_poisson <- rpois(n, exp(eta)) result <- univariate_irls_glm(x, y_poisson, poisson(), offset=numeric(0)) print(result)  # Binomial example prob <- 1/(1 + exp(-(0.5 + 0.8*x))) y_binomial <- rbinom(n, 1, prob) result <- univariate_irls_glm(x, y_binomial, binomial(), offset=numeric(0)) print(result) } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_glm_no_intercept.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Univariate GLM Without Intercept Using IRLS — univariate_irls_glm_no_intercept","title":"Fit a Univariate GLM Without Intercept Using IRLS — univariate_irls_glm_no_intercept","text":"Fits generalized linear model (GLM) using single covariate intercept term via iteratively reweighted least squares (IRLS) algorithm.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_glm_no_intercept.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a Univariate GLM Without Intercept Using IRLS — univariate_irls_glm_no_intercept","text":"x Numeric vector length n: predictor values. y Numeric vector length n: response values. family R family object, binomial(), poisson(), gaussian(). offset Numeric vector length 1 n, default 0. Optional offset linear predictor. max_iter Integer. Maximum number IRLS iterations (default = 25). tol Numeric. Convergence tolerance (default = 1e-8).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_glm_no_intercept.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a Univariate GLM Without Intercept Using IRLS — univariate_irls_glm_no_intercept","text":"Numeric scalar: estimated slope \\(\\theta\\).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_glm_no_intercept.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a Univariate GLM Without Intercept Using IRLS — univariate_irls_glm_no_intercept","text":"linear predictor defined : $$\\eta = \\theta \\cdot x + \\mathrm{offset}$$ \\(g(\\mu) = \\eta\\) canonical link function specified GLM family. function uses R's family object (e.g., binomial(), poisson(), gaussian()) evaluate inverse link, variance, derivative functions iteration. Numerical safeguards included: linear predictor eta clamped Poisson models prevent overflow. Variance derivative evaluations floored avoid division zero. Extremely large weights capped.","code":""},{"path":[]},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_irls_glm_no_intercept.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a Univariate GLM Without Intercept Using IRLS — univariate_irls_glm_no_intercept","text":"","code":"if (FALSE) { # \\dontrun{ x <- rnorm(100) y <- rbinom(100, 1, plogis(2 * x)) univariate_irls_glm_no_intercept(x, y, family = binomial())  x <- rnorm(100) y <- 1 + 3 * x + rnorm(100) univariate_irls_glm_no_intercept(x, y, family = gaussian()) } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Univariate Log-Likelihood for GLM or Cox Model — univariate_loglik","title":"Compute Univariate Log-Likelihood for GLM or Cox Model — univariate_loglik","text":"Calculates log-likelihood single covariate effect either generalized linear model (GLM) family Cox proportional hazards model.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Univariate Log-Likelihood for GLM or Cox Model — univariate_loglik","text":"x Numeric vector length n: covariate values. y GLMs: numeric vector length n; Cox: numeric matrix two columns (time, status) n rows. family GLM family object (e.g. gaussian(), binomial(), poisson()) Cox family list element family=\"cox\". theta Numeric scalar: coefficient evaluate log-likelihood. offset Numeric scalar vector length n: offset linear predictor. intercept Numeric scalar: intercept term linear predictor (GLM ). Default 0. ties Character string: tie-handling method Cox partial likelihood; one \"efron\" \"breslow\".","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Univariate Log-Likelihood for GLM or Cox Model — univariate_loglik","text":"numeric scalar giving log-likelihood univariate fit.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Univariate Log-Likelihood for GLM or Cox Model — univariate_loglik","text":"","code":"if (FALSE) { # \\dontrun{ # Gaussian example x <- rnorm(100) y <- 1.5 + 2 * x + rnorm(100) univariate_loglik(x, y, family = gaussian(), theta = 2, intercept = 1.5)  # Binomial example x <- rnorm(200) eta <- -1 + 1.5 * x p <- plogis(eta) y <- rbinom(200, 1, p) univariate_loglik(x, y, family = binomial(link = \"logit\"),                   theta = 1.5, intercept = -1)  # Cox example (note: intercept not used in Cox models) x <- rnorm(50) times <- rexp(50) status <- rbinom(50, 1, 0.5) ymat <- cbind(times, status) univariate_loglik(x, ymat, family = list(family = \"cox\"),                   theta = 0.5, offset = 0, ties = \"efron\") } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","title":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","text":"Computes partial log-likelihood univariate Cox proportional hazards model. Handles ties using either Breslow Efron approximation.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","text":"x Numeric vector length n: covariate values individual. y Numeric matrix shape n × 2, : - y[,1] contains event/censoring times - y[,2] contains event status (1 = event, 0 = censored) theta Numeric scalar: coefficient evaluate log-likelihood . offset Numeric vector length n, scalar. Optional offset linear predictor. ties Character string: tie-handling method. Must either \"breslow\" \"efron\".","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik_cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","text":"Numeric scalar: partial log-likelihood value.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik_cox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","text":"function computes linear predictor : lp = offset + theta * x. partial log-likelihood calculated using either Breslow Efron method handling tied event times.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik_cox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","text":"","code":"if (FALSE) { # \\dontrun{ x <- c(1, 2, 3, 4) y <- matrix(c(4,1, 1,1, 3,0, 2,1), ncol = 2, byrow = TRUE) univariate_loglik_cox(x, y, offset = 0, theta = 0.5, ties = \"efron\") } # }"},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Log-Likelihood for Univariate GLM — univariate_loglik_glm","title":"Compute Log-Likelihood for Univariate GLM — univariate_loglik_glm","text":"Computes log-likelihood univariate generalized linear model (GLM) single covariate, intercept, optional offset. Supports family stats::family() (e.g.\\ Gaussian, Binomial, Poisson).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Log-Likelihood for Univariate GLM — univariate_loglik_glm","text":"x Numeric vector length n: single covariate. y Numeric vector length n: response values (Binomial, can 0/1 two-column matrix counts). family R family object (stats::family(), default gaussian()). theta Numeric scalar: coefficient evaluate log-likelihood. offset Numeric vector length n, scalar, default 0: optional offset linear predictor. intercept Numeric scalar: intercept term linear predictor, default 0.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Log-Likelihood for Univariate GLM — univariate_loglik_glm","text":"Numeric scalar: (profiled) log-likelihood theta intercept.","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik_glm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Log-Likelihood for Univariate GLM — univariate_loglik_glm","text":"function forms linear predictor η = intercept + offset + θ * x, uses family's linkinv dev.resids functions compute deviance residuals d_i.  log-likelihood $$\\ell = -\\,\\sum_i d_i / 2,$$ profiling dispersion families estimate (Gaussian, Gamma, inverse.gaussian) leaving fixed others (Binomial, Poisson).","code":""},{"path":"https://yizenglistat.github.io/glmsusie/reference/univariate_loglik_glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Log-Likelihood for Univariate GLM — univariate_loglik_glm","text":"","code":"if (FALSE) { # \\dontrun{ x <- rnorm(100) y <- 1.5 + 2 * x + rnorm(100) univariate_loglik_glm(x, y, family = gaussian(), theta = 2, intercept = 1.5)  x <- runif(200, -2, 2) p <- plogis(0.5 + 1.5 * x) y_bin <- rbinom(200, 1, p) univariate_loglik_glm(x, y_bin, family = binomial(), theta = 1.5, intercept = 0.5)  x_p <- rpois(150, lambda = 2) mu <- exp(-1 + 0.3 * x_p) y_p <- rpois(150, mu) univariate_loglik_glm(x_p, y_p, family = poisson(), theta = 0.3, intercept = -1) } # }"}]
