[{"path":"https://yizenglistat.github.io/glmcs/articles/cox.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Cox Regression Examples","text":"glmcs package implements likelihood-based additive single-sffect regression (LASER), sparse model represents overall effect sum small number single-effect components. vignette : Simulate high-dimensional sparse Gaussian linear regression model Fit Gaussian LASER model via glmcs() Visualize coefficient esimates, inclusion probabilities, confidence sets Evaluate predictive performance vs. SuSiE","code":""},{"path":"https://yizenglistat.github.io/glmcs/articles/cox.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"Cox Regression Examples","text":"generate (n=1000) observations (p=1000) variables, 4 true active (nonzero) effects.","code":"set.seed(42) n <- 1000    # sample size p <- 1000    # number of predictors L <- 10      # number of single-effect components  # true sparse coefficients theta_true <- rep(0, p) theta_true[c(100, 200, 300, 400)] <- 1  # covariate matrix and response X <- matrix(rnorm(n * p), nrow = n, ncol = p) y <- drop(X %*% theta_true + rnorm(n))"},{"path":"https://yizenglistat.github.io/glmcs/articles/cox.html","id":"fit-the-laser-model","dir":"Articles","previous_headings":"","what":"Fit the LASER model","title":"Cox Regression Examples","text":"allow (L=10) single effects use default Gaussian family. Generally, method robust larger L values present minimal risk overfitting.","code":"# load glmcs library library(glmcs)  # model fitting fit <- glmcs(   X              = X,   y              = y,   L              = L,   family         = gaussian() ) summary(fit) #  # Call: # glmcs(X = X, y = y, L = L, family = gaussian()) #  # Family: gaussian  #  # Coefficients: (sorted by magnitude) #      Estimate MarginProb # X300   1.0363          1 # X200   1.0082          1 # X100   0.9661          1 # X400   0.9505          1 # X1     0.0000          0 # X2     0.0000          0 # X3     0.0000          0 # X4     0.0000          0 # X5     0.0000          0 # X6     0.0000          0 # ... (990 more coefficients not shown) #  # 95% Confidence Sets: #       Set Coverage # cs1 {300}        1 # cs2 {200}        1 # cs3 {400}        1 # cs4 {100}        1 #  # Dispersion parameter: 0.9343  #  # Model converged after 3 iterations. # Computation time: 12.79 seconds."},{"path":[]},{"path":"https://yizenglistat.github.io/glmcs/articles/cox.html","id":"coefficient-estimates","dir":"Articles","previous_headings":"Results","what":"Coefficient estimates","title":"Cox Regression Examples","text":"recover four peaks true locations","code":"# plot coefficients plot(fit, which=\"coefficients\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/cox.html","id":"estimated-inclusion-probability","dir":"Articles","previous_headings":"Results","what":"Estimated inclusion probability","title":"Cox Regression Examples","text":"Shows inclusion probability variable included single-effect component:","code":"# plot coefficients plot(fit, which=\"probabilities\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/cox.html","id":"estimated-95-confidence-sets","dir":"Articles","previous_headings":"Results","what":"Estimated 95% confidence sets","title":"Cox Regression Examples","text":"confidence set (CS) contains small group variables least one likely active, 95\\% confidence.","code":"# plot coefficients plot(fit, which=\"sets\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/cox.html","id":"performance-evalution","dir":"Articles","previous_headings":"Results","what":"Performance evalution","title":"Cox Regression Examples","text":"","code":"# compare with SuSiE fitted_susie  <- fitted(susieR::susie(X, y, L)) fitted_glmcs  <- fitted(fit) rmse_susie    <- sqrt(mean((y - fitted_susie)^2)) rmse_glmcs    <- sqrt(mean((y - fitted_glmcs)^2))  data.frame(   Method = c(\"susie\", \"glmcs\"),   RMSE   = c(rmse_susie, rmse_glmcs) ) #   Method      RMSE # 1  susie 0.9728844 # 2  glmcs 0.9728829"},{"path":"https://yizenglistat.github.io/glmcs/articles/gaussian.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Gaussian Regression Examples","text":"glmcs package implements likelihood-based additive single-sffect regression (LASER), sparse model represents overall effect sum small number single-effect components. vignette : Simulate high-dimensional sparse Gaussian linear regression model Fit Gaussian LASER model via glmcs() Visualize coefficient esimates, inclusion probabilities, confidence sets Evaluate predictive performance vs. SuSiE","code":""},{"path":"https://yizenglistat.github.io/glmcs/articles/gaussian.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"Gaussian Regression Examples","text":"generate (n=1000) observations (p=1000) variables, 4 true active (nonzero) effects.","code":"set.seed(42) n <- 1000    # sample size p <- 1000    # number of predictors L <- 10      # number of single-effect components  # true sparse coefficients theta_true <- rep(0, p) theta_true[c(100, 200, 300, 400)] <- 1  # covariate matrix and response X <- matrix(rnorm(n * p), nrow = n, ncol = p) y <- drop(X %*% theta_true + rnorm(n))"},{"path":"https://yizenglistat.github.io/glmcs/articles/gaussian.html","id":"fit-the-laser-model","dir":"Articles","previous_headings":"","what":"Fit the LASER model","title":"Gaussian Regression Examples","text":"allow (L=10) single effects use default Gaussian family. Generally, method robust larger L values present minimal risk overfitting.","code":"# load glmcs library library(glmcs)  # model fitting fit <- glmcs(   X              = X,   y              = y,   L              = L,   family         = gaussian() ) summary(fit) #  # Call: # glmcs(X = X, y = y, L = L, family = gaussian()) #  # Family: gaussian  #  # Coefficients: (sorted by magnitude) #      Estimate MarginProb # X300   1.0363          1 # X200   1.0082          1 # X100   0.9661          1 # X400   0.9505          1 # X1     0.0000          0 # X2     0.0000          0 # X3     0.0000          0 # X4     0.0000          0 # X5     0.0000          0 # X6     0.0000          0 # ... (990 more coefficients not shown) #  # 95% Confidence Sets: #       Set Coverage # cs1 {300}        1 # cs2 {200}        1 # cs3 {400}        1 # cs4 {100}        1 #  # Dispersion parameter: 0.9343  #  # Model converged after 3 iterations. # Computation time: 12.77 seconds."},{"path":[]},{"path":"https://yizenglistat.github.io/glmcs/articles/gaussian.html","id":"coefficient-estimates","dir":"Articles","previous_headings":"Results","what":"Coefficient estimates","title":"Gaussian Regression Examples","text":"recover four peaks true locations","code":"# plot coefficients plot(fit, which=\"coefficients\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/gaussian.html","id":"estimated-inclusion-probability","dir":"Articles","previous_headings":"Results","what":"Estimated inclusion probability","title":"Gaussian Regression Examples","text":"Shows inclusion probability variable included single-effect component:","code":"# plot coefficients plot(fit, which=\"probabilities\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/gaussian.html","id":"estimated-95-confidence-sets","dir":"Articles","previous_headings":"Results","what":"Estimated 95% confidence sets","title":"Gaussian Regression Examples","text":"confidence set (CS) contains small group variables least one likely active, 95\\% confidence.","code":"# plot coefficients plot(fit, which=\"sets\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/gaussian.html","id":"performance-evalution","dir":"Articles","previous_headings":"Results","what":"Performance evalution","title":"Gaussian Regression Examples","text":"","code":"# compare with SuSiE fitted_susie  <- fitted(susieR::susie(X, y, L)) fitted_glmcs  <- fitted(fit) rmse_susie    <- sqrt(mean((y - fitted_susie)^2)) rmse_glmcs    <- sqrt(mean((y - fitted_glmcs)^2))  data.frame(   Method = c(\"susie\", \"glmcs\"),   RMSE   = c(rmse_susie, rmse_glmcs) ) #   Method      RMSE # 1  susie 0.9728844 # 2  glmcs 0.9728829"},{"path":"https://yizenglistat.github.io/glmcs/articles/logit.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Logistic Regression Examples","text":"glmcs package implements likelihood-based additive single-sffect regression (LASER), sparse model represents overall effect sum small number single-effect components. vignette : Simulate high-dimensional sparse Gaussian linear regression model Fit Gaussian LASER model via glmcs() Visualize coefficient esimates, inclusion probabilities, confidence sets Evaluate predictive performance vs. SuSiE","code":""},{"path":"https://yizenglistat.github.io/glmcs/articles/logit.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"Logistic Regression Examples","text":"generate (n=1000) observations (p=1000) variables, 4 true active (nonzero) effects.","code":"set.seed(42) n <- 1000    # sample size p <- 1000    # number of predictors L <- 10      # number of single-effect components  # true sparse coefficients theta_true <- rep(0, p) theta_true[c(100, 200, 300, 400)] <- 1  # covariate matrix and response X <- matrix(rnorm(n * p), nrow = n, ncol = p) y <- drop(X %*% theta_true + rnorm(n))"},{"path":"https://yizenglistat.github.io/glmcs/articles/logit.html","id":"fit-the-laser-model","dir":"Articles","previous_headings":"","what":"Fit the LASER model","title":"Logistic Regression Examples","text":"allow (L=10) single effects use default Gaussian family. Generally, method robust larger L values present minimal risk overfitting.","code":"# load glmcs library library(glmcs)  # model fitting fit <- glmcs(   X              = X,   y              = y,   L              = L,   family         = gaussian() ) summary(fit) #  # Call: # glmcs(X = X, y = y, L = L, family = gaussian()) #  # Family: gaussian  #  # Coefficients: (sorted by magnitude) #      Estimate MarginProb # X300   1.0363          1 # X200   1.0082          1 # X100   0.9661          1 # X400   0.9505          1 # X1     0.0000          0 # X2     0.0000          0 # X3     0.0000          0 # X4     0.0000          0 # X5     0.0000          0 # X6     0.0000          0 # ... (990 more coefficients not shown) #  # 95% Confidence Sets: #       Set Coverage # cs1 {300}        1 # cs2 {200}        1 # cs3 {400}        1 # cs4 {100}        1 #  # Dispersion parameter: 0.9343  #  # Model converged after 3 iterations. # Computation time: 11.99 seconds."},{"path":[]},{"path":"https://yizenglistat.github.io/glmcs/articles/logit.html","id":"coefficient-estimates","dir":"Articles","previous_headings":"Results","what":"Coefficient estimates","title":"Logistic Regression Examples","text":"recover four peaks true locations","code":"# plot coefficients plot(fit, which=\"coefficients\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/logit.html","id":"estimated-inclusion-probability","dir":"Articles","previous_headings":"Results","what":"Estimated inclusion probability","title":"Logistic Regression Examples","text":"Shows inclusion probability variable included single-effect component:","code":"# plot coefficients plot(fit, which=\"probabilities\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/logit.html","id":"estimated-95-confidence-sets","dir":"Articles","previous_headings":"Results","what":"Estimated 95% confidence sets","title":"Logistic Regression Examples","text":"confidence set (CS) contains small group variables least one likely active, 95\\% confidence.","code":"# plot coefficients plot(fit, which=\"sets\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/logit.html","id":"performance-evalution","dir":"Articles","previous_headings":"Results","what":"Performance evalution","title":"Logistic Regression Examples","text":"","code":"# compare with SuSiE fitted_susie  <- fitted(susieR::susie(X, y, L)) fitted_glmcs  <- fitted(fit) rmse_susie    <- sqrt(mean((y - fitted_susie)^2)) rmse_glmcs    <- sqrt(mean((y - fitted_glmcs)^2))  data.frame(   Method = c(\"susie\", \"glmcs\"),   RMSE   = c(rmse_susie, rmse_glmcs) ) #   Method      RMSE # 1  susie 0.9728844 # 2  glmcs 0.9728829"},{"path":"https://yizenglistat.github.io/glmcs/articles/mwe.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"A Minimal Example","text":"glmcs package implements likelihood-based additive single-sffect regression (LASER), sparse model represents overall effect sum small number single-effect components. vignette : Simulate high-dimensional sparse Gaussian linear regression model Fit Gaussian LASER model via glmcs() Visualize coefficient esimates, inclusion probabilities, confidence sets Evaluate predictive performance vs. SuSiE","code":""},{"path":"https://yizenglistat.github.io/glmcs/articles/mwe.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"A Minimal Example","text":"generate (n=1000) observations (p=1000) variables, 4 true active (nonzero) effects.","code":"set.seed(42) n <- 1000    # sample size p <- 1000    # number of predictors L <- 10      # number of single-effect components  # true sparse coefficients theta_true <- rep(0, p) theta_true[c(100, 200, 300, 400)] <- 1  # covariate matrix and response X <- matrix(rnorm(n * p), nrow = n, ncol = p) y <- drop(X %*% theta_true + rnorm(n))"},{"path":"https://yizenglistat.github.io/glmcs/articles/mwe.html","id":"fit-the-laser-model","dir":"Articles","previous_headings":"","what":"Fit the LASER model","title":"A Minimal Example","text":"allow (L=10) single effects use default Gaussian family. Generally, method robust larger L values present minimal risk overfitting.","code":"# load glmcs library library(glmcs)  # model fitting fit <- glmcs(   X              = X,   y              = y,   L              = L,   family         = gaussian() ) summary(fit) #  # Call: # glmcs(X = X, y = y, L = L, family = gaussian()) #  # Family: gaussian  #  # Coefficients: (sorted by magnitude) #      Estimate MarginProb # X300   1.0363          1 # X200   1.0082          1 # X100   0.9661          1 # X400   0.9505          1 # X1     0.0000          0 # X2     0.0000          0 # X3     0.0000          0 # X4     0.0000          0 # X5     0.0000          0 # X6     0.0000          0 # ... (990 more coefficients not shown) #  # 95% Confidence Sets: #       Set Coverage # cs1 {300}        1 # cs2 {200}        1 # cs3 {400}        1 # cs4 {100}        1 #  # Dispersion parameter: 0.9343  #  # Model converged after 3 iterations. # Computation time: 12.87 seconds."},{"path":[]},{"path":"https://yizenglistat.github.io/glmcs/articles/mwe.html","id":"coefficient-estimates","dir":"Articles","previous_headings":"Results","what":"Coefficient estimates","title":"A Minimal Example","text":"recover four peaks true locations","code":"# plot coefficients plot(fit, which=\"coefficients\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/mwe.html","id":"estimated-inclusion-probability","dir":"Articles","previous_headings":"Results","what":"Estimated inclusion probability","title":"A Minimal Example","text":"Shows inclusion probability variable included single-effect component:","code":"# plot coefficients plot(fit, which=\"probabilities\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/mwe.html","id":"estimated-95-confidence-sets","dir":"Articles","previous_headings":"Results","what":"Estimated 95% confidence sets","title":"A Minimal Example","text":"confidence set (CS) contains small group variables least one likely active, 95\\% confidence.","code":"# plot coefficients plot(fit, which=\"sets\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/mwe.html","id":"performance-evalution","dir":"Articles","previous_headings":"Results","what":"Performance evalution","title":"A Minimal Example","text":"","code":"# compare with SuSiE fitted_susie  <- fitted(susieR::susie(X, y, L)) fitted_glmcs  <- fitted(fit) rmse_susie    <- sqrt(mean((y - fitted_susie)^2)) rmse_glmcs    <- sqrt(mean((y - fitted_glmcs)^2))  data.frame(   Method = c(\"susie\", \"glmcs\"),   RMSE   = c(rmse_susie, rmse_glmcs) ) #   Method      RMSE # 1  susie 0.9728844 # 2  glmcs 0.9728829"},{"path":"https://yizenglistat.github.io/glmcs/articles/poisson.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Poisson Regression Examples","text":"glmcs package implements likelihood-based additive single-sffect regression (LASER), sparse model represents overall effect sum small number single-effect components. vignette : Simulate high-dimensional sparse Gaussian linear regression model Fit Gaussian LASER model via glmcs() Visualize coefficient esimates, inclusion probabilities, confidence sets Evaluate predictive performance vs. SuSiE","code":""},{"path":"https://yizenglistat.github.io/glmcs/articles/poisson.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"Poisson Regression Examples","text":"generate (n=1000) observations (p=1000) variables, 4 true active (nonzero) effects.","code":"set.seed(42) n <- 1000    # sample size p <- 1000    # number of predictors L <- 10      # number of single-effect components  # true sparse coefficients theta_true <- rep(0, p) theta_true[c(100, 200, 300, 400)] <- 1  # covariate matrix and response X <- matrix(rnorm(n * p), nrow = n, ncol = p) y <- drop(X %*% theta_true + rnorm(n))"},{"path":"https://yizenglistat.github.io/glmcs/articles/poisson.html","id":"fit-the-laser-model","dir":"Articles","previous_headings":"","what":"Fit the LASER model","title":"Poisson Regression Examples","text":"allow (L=10) single effects use default Gaussian family. Generally, method robust larger L values present minimal risk overfitting.","code":"# load glmcs library library(glmcs)  # model fitting fit <- glmcs(   X              = X,   y              = y,   L              = L,   family         = gaussian() ) summary(fit) #  # Call: # glmcs(X = X, y = y, L = L, family = gaussian()) #  # Family: gaussian  #  # Coefficients: (sorted by magnitude) #      Estimate MarginProb # X300   1.0363          1 # X200   1.0082          1 # X100   0.9661          1 # X400   0.9505          1 # X1     0.0000          0 # X2     0.0000          0 # X3     0.0000          0 # X4     0.0000          0 # X5     0.0000          0 # X6     0.0000          0 # ... (990 more coefficients not shown) #  # 95% Confidence Sets: #       Set Coverage # cs1 {300}        1 # cs2 {200}        1 # cs3 {400}        1 # cs4 {100}        1 #  # Dispersion parameter: 0.9343  #  # Model converged after 3 iterations. # Computation time: 12.82 seconds."},{"path":[]},{"path":"https://yizenglistat.github.io/glmcs/articles/poisson.html","id":"coefficient-estimates","dir":"Articles","previous_headings":"Results","what":"Coefficient estimates","title":"Poisson Regression Examples","text":"recover four peaks true locations","code":"# plot coefficients plot(fit, which=\"coefficients\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/poisson.html","id":"estimated-inclusion-probability","dir":"Articles","previous_headings":"Results","what":"Estimated inclusion probability","title":"Poisson Regression Examples","text":"Shows inclusion probability variable included single-effect component:","code":"# plot coefficients plot(fit, which=\"probabilities\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/poisson.html","id":"estimated-95-confidence-sets","dir":"Articles","previous_headings":"Results","what":"Estimated 95% confidence sets","title":"Poisson Regression Examples","text":"confidence set (CS) contains small group variables least one likely active, 95\\% confidence.","code":"# plot coefficients plot(fit, which=\"sets\")"},{"path":"https://yizenglistat.github.io/glmcs/articles/poisson.html","id":"performance-evalution","dir":"Articles","previous_headings":"Results","what":"Performance evalution","title":"Poisson Regression Examples","text":"","code":"# compare with SuSiE fitted_susie  <- fitted(susieR::susie(X, y, L)) fitted_glmcs  <- fitted(fit) rmse_susie    <- sqrt(mean((y - fitted_susie)^2)) rmse_glmcs    <- sqrt(mean((y - fitted_glmcs)^2))  data.frame(   Method = c(\"susie\", \"glmcs\"),   RMSE   = c(rmse_susie, rmse_glmcs) ) #   Method      RMSE # 1  susie 0.9728844 # 2  glmcs 0.9728829"},{"path":[]},{"path":"https://yizenglistat.github.io/glmcs/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Yizeng Li. Author, maintainer. Wei Pan. Author.","code":""},{"path":"https://yizenglistat.github.io/glmcs/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Li Y, Pan W (2025). glmcs: Generalized Linear Models Confident Sets. R package version 0.1.0, https://github.com/yizenglistat/glmcs.","code":"@Manual{,   title = {glmcs: Generalized Linear Models with Confident Sets},   author = {Yizeng Li and Wei Pan},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/yizenglistat/glmcs}, }"},{"path":"https://yizenglistat.github.io/glmcs/index.html","id":"about","dir":"","previous_headings":"","what":"About","title":"Generalized Linear Models with Confident Sets","text":"glmcs package provides innovative approach variable selection generalized linear models regression frameworks, including Cox regression survival analysis. method excels predictors highly correlated true model sparse. core, glmcs implements “Likelihood-based Additive Single-Effect Regression” (LASER) model – novel sparse regression approach essentially enhances traditional forward selection. algorithm produces “Confidence Sets” (CSs), groups correlated variables high probability containing least one non-zero effect. confidence sets offer statistical guarantee variable importance acknowledging inherent uncertainty highly correlated predictor spaces. Rather forcing selection single variable might unstable, CS approach identifies groups can confident least one variable influential. Developed Yizeng Li Wei Pan Division Biostatistics University Minnesota Twin Cities.","code":""},{"path":"https://yizenglistat.github.io/glmcs/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick start","title":"Generalized Linear Models with Confident Sets","text":"can install released version glmcs CRAN: Alternatively, install latest development version glmcs Github: See brief illustraton glmcs. documentation examples please visit https://github.com/yizenglistat/glmcs.","code":"install.packages(\"glmcs\") # install.packages(\"remotes\") remotes::install_github(\"yizenglistat/glmcs\")"},{"path":"https://yizenglistat.github.io/glmcs/reference/AIC.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract AIC from a glmcs Object — AIC.glmcs","title":"Extract AIC from a glmcs Object — AIC.glmcs","text":"Returns Akaike Information Criterion (AIC) glmcs model.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/AIC.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract AIC from a glmcs Object — AIC.glmcs","text":"","code":"# S3 method for class 'glmcs' AIC(object, ..., k = 2)"},{"path":"https://yizenglistat.github.io/glmcs/reference/AIC.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract AIC from a glmcs Object — AIC.glmcs","text":"object fitted model object class \"glmcs\". ... Additional arguments (used). k Numeric, penalty per parameter used; default 2.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/AIC.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract AIC from a glmcs Object — AIC.glmcs","text":"AIC value.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/BIC.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract BIC from a glmcs Object — BIC.glmcs","title":"Extract BIC from a glmcs Object — BIC.glmcs","text":"Returns Bayesian Information Criterion (BIC) glmcs model.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/BIC.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract BIC from a glmcs Object — BIC.glmcs","text":"","code":"# S3 method for class 'glmcs' BIC(object, ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/BIC.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract BIC from a glmcs Object — BIC.glmcs","text":"object fitted model object class \"glmcs\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/BIC.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract BIC from a glmcs Object — BIC.glmcs","text":"BIC value.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/additive_effect_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Likelihood-based Additive Single-Effect Regression (LASER) Model — additive_effect_fit","title":"Fit Likelihood-based Additive Single-Effect Regression (LASER) Model — additive_effect_fit","text":"Fits LASER model, representing coefficient vector sum L sparse \"single effects.\"  iteration, cyclically applies single_effect_fit update one effect holding others fixed, updates intercept (dispersion, applicable), convergence max_iter reached.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/additive_effect_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Likelihood-based Additive Single-Effect Regression (LASER) Model — additive_effect_fit","text":"X Numeric matrix (n × p) predictors. y Response: GLMs: numeric vector length n. Cox: numeric matrix 2 columns (time, status) n rows. L Integer; number single effects include (set min(10, L)). family stats::family object (e.g. gaussian(), binomial(), poisson()) Cox family list family = \"cox\". standardize Logical: TRUE, center scale predictor column fitting (default: TRUE). ties Character: ties method Cox partial likelihood (\"efron\" \"breslow\", default: \"efron\"). lambda Numeric penalty weight; ≤ 0, defaults \\(\\sqrt{2\\log(n)/n}\\) (default: 0.0). tau Numeric truncation parameter; ≤ 0, defaults 0.5 (default: 0.5). null_threshold Numeric threshold estimated coefficient set zero (default: 1e-6). tol Numeric; convergence tolerance change expected log-likelihood (default: 5e-2). max_iter Integer; maximum number coordinate-ascent iterations (default: 100).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/additive_effect_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Likelihood-based Additive Single-Effect Regression (LASER) Model — additive_effect_fit","text":"list components: niter Number iterations performed. loglik p × L matrix univariate log-likelihoods. expect_loglik Vector length niter giving expected log-likelihood iteration. final_loglik Expected log-likelihood convergence. intercept Estimated intercept term. dispersion Estimated dispersion parameter (Gaussian/Gamma). theta p × L matrix fitted single-effect coefficients. pmp p × L matrix posterior model probabilities. bic p × L matrix BIC values. bic_diff p × L matrix BIC differences null. bf p × L matrix Bayes factors. expect_variance Length-L vector PMP-weighted variances. kept Logical vector length L; TRUE effects retained. elapsed_time Numeric; total computation time seconds.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/additive_effect_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Likelihood-based Additive Single-Effect Regression (LASER) Model — additive_effect_fit","text":"","code":"if (FALSE) { # \\dontrun{ # Gaussian example with 5 effects X <- matrix(rnorm(100*20), 100, 20) y <- rnorm(100) res <- additive_effect_fit(X, y, L = 5, family = gaussian())  # Cox regression example times  <- rexp(100) status <- rbinom(100, 1, 0.5) y_cox  <- cbind(times, status) res_cox <- additive_effect_fit(X, y_cox, L = 3,                                family = list(family = \"cox\"),                                ties = \"breslow\") } # }"},{"path":"https://yizenglistat.github.io/glmcs/reference/coef.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Model Coefficients from a glmcs Object — coef.glmcs","title":"Extract Model Coefficients from a glmcs Object — coef.glmcs","text":"Extracts coefficients glmcs model fit summing coefficients across single effects predictor.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/coef.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Model Coefficients from a glmcs Object — coef.glmcs","text":"","code":"# S3 method for class 'glmcs' coef(object, intercept = FALSE, ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/coef.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Model Coefficients from a glmcs Object — coef.glmcs","text":"object fitted model object class \"glmcs\". intercept Logical; TRUE, include intercept term first element returned vector. Default FALSE. ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/coef.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Model Coefficients from a glmcs Object — coef.glmcs","text":"numeric vector coefficients, names corresponding column names design matrix. intercept = TRUE, first element named \"(Intercept)\".","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/confidence_set.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","title":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","text":"latent effect (column) posterior model probability matrix pmp, select smallest set variables whose cumulative probability reaches least coverage.  Optionally filter sets whose minimum absolute pairwise correlation (Rmat) cor_threshold, remove duplicates.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/confidence_set.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","text":"","code":"confidence_set(pmp, kept, coverage = 0.95, Rmat = NULL, cor_threshold = 0.5)"},{"path":"https://yizenglistat.github.io/glmcs/reference/confidence_set.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","text":"pmp Numeric matrix dimension \\(p \\times L\\), column sums 1 contains posterior inclusion probabilities variable effect. kept Logical vector length \\(L\\), indicating effects (columns) process. coverage Numeric scalar [0,1], target cumulative probability confidence set. Defaults 0.95. Rmat Optional \\(p \\times p\\) numeric correlation matrix predictors. supplied, set whose minimum -diagonal absolute correlation cor_threshold discarded.  Defaults NULL. cor_threshold Numeric scalar [0,1], minimum absolute correlation allowed within set pass correlation filter.  Defaults 0.5.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/confidence_set.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","text":"list components: sets named list integer vectors.  element cs1, cs2, … confidence set variable indices achieves target coverage.  sets survive filters, sets NULL. claimed Numeric vector actual cumulative probabilities (\"claimed coverage\") returned set.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/confidence_set.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct Confidence Sets from Posterior Model Probabilities — confidence_set","text":"","code":"# Simple two-effect example pmp <- matrix(c(0.6, 0.3, 0.1,                 0.2, 0.5, 0.3),               nrow = 3, byrow = FALSE) kept <- c(TRUE, TRUE) cs <- confidence_set(pmp, kept)  # With a correlation filter Rmat <- cor(matrix(rnorm(9), nrow = 3)) cs2 <- confidence_set(pmp, kept, coverage = 0.8, Rmat = Rmat, cor_threshold = 0.2)"},{"path":"https://yizenglistat.github.io/glmcs/reference/cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Cox Proportional Hazards ","title":"Cox Proportional Hazards ","text":"Creates family object univariate Cox regression, compatible GLM‐style interfaces.  log link supported, yielding usual Cox partial‐likelihood formulation.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cox Proportional Hazards ","text":"","code":"cox(link = \"log\")"},{"path":"https://yizenglistat.github.io/glmcs/reference/cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cox Proportional Hazards ","text":"link Character string; link function Cox model.  \"log\" supported (default).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cox Proportional Hazards ","text":"family object (list class \"family\") containing: family Always \"cox\". link Link name, \"log\". linkfun Function transforming mu eta. linkinv Inverse link, mapping eta mu. mu.eta Derivative linkinv. variance Variance function (returns 1). dev.resids Deviance residuals (zeros). aic AIC placeholder (returns -2). validmu, valideta Validation functions (always TRUE). dispersion Always 1.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/cox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cox Proportional Hazards ","text":"\"family\" object provides minimal set functions required use IRLS‐based routines log-likelihood calculations: linkfun linkinv implement log link. mu.eta provides derivative inverse link. variance, dev.resids, aic placeholders (used Cox needed compatibility).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/cox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cox Proportional Hazards ","text":"","code":"# Create the Cox family object fam <- cox(link = \"log\") stopifnot(fam$family == \"cox\") # Check that linkinv(exp(eta)) == exp(eta) eta <- c(0, 1, -1) all.equal(fam$linkinv(eta), exp(eta)) #> [1] TRUE"},{"path":"https://yizenglistat.github.io/glmcs/reference/deviance.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Deviance for a glmcs Object — deviance.glmcs","title":"Calculate Deviance for a glmcs Object — deviance.glmcs","text":"Returns deviance glmcs model.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/deviance.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Deviance for a glmcs Object — deviance.glmcs","text":"","code":"# S3 method for class 'glmcs' deviance(object, ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/deviance.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Deviance for a glmcs Object — deviance.glmcs","text":"object fitted model object class \"glmcs\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/deviance.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Deviance for a glmcs Object — deviance.glmcs","text":"Deviance value.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/dispersion.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Dispersion Parameter from a glmcs Object — dispersion.glmcs","title":"Extract Dispersion Parameter from a glmcs Object — dispersion.glmcs","text":"Returns estimated dispersion parameter glmcs model.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/dispersion.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Dispersion Parameter from a glmcs Object — dispersion.glmcs","text":"","code":"dispersion.glmcs(object, ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/dispersion.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Dispersion Parameter from a glmcs Object — dispersion.glmcs","text":"object fitted model object class \"glmcs\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/dispersion.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Dispersion Parameter from a glmcs Object — dispersion.glmcs","text":"Dispersion parameter value.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/fitted.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Fitted Values from a glmcs Object — fitted.glmcs","title":"Extract Fitted Values from a glmcs Object — fitted.glmcs","text":"Returns fitted values glmcs model object.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/fitted.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Fitted Values from a glmcs Object — fitted.glmcs","text":"","code":"# S3 method for class 'glmcs' fitted(object, ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/fitted.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Fitted Values from a glmcs Object — fitted.glmcs","text":"object fitted model object class \"glmcs\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/fitted.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Fitted Values from a glmcs Object — fitted.glmcs","text":"vector fitted values scale response variable.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/generate.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Synthetic Data for Benchmark Simulations — generate","title":"Generate Synthetic Data for Benchmark Simulations — generate","text":"Creates design matrix X controlled correlation structure simulates response y according specified family.  Supports Gaussian, Binomial, Poisson, Gamma GLMs, Cox survival data exponential baseline hazard.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/generate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Synthetic Data for Benchmark Simulations — generate","text":"","code":"generate(   n = 600,   theta = c(1, 0),   intercept = 0,   settings = c(\"ex1\", \"ex2\", \"ex3\"),   rho = 0.9,   dispersion = 1,   family = gaussian(),   censoring_rate = 0.3,   baseline_hazard = 1 )"},{"path":"https://yizenglistat.github.io/glmcs/reference/generate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Synthetic Data for Benchmark Simulations — generate","text":"n Integer; number observations (default: 600). theta Numeric vector true coefficients (length p). intercept Numeric; true intercept term (default: 0). settings Character; correlation pattern: \"ex1\": p variables equally correlated. \"ex2\": first 5×5 block correlated, others independent. \"ex3\": two p/2 × p/2 blocks correlated. Default: c(\"ex1\",\"ex2\",\"ex3\"). rho Numeric [0,1]; within-block correlation (default: 0.9). dispersion Numeric; dispersion Gaussian/Gamma (default: 1). family family object (e.g. gaussian(), binomial(), poisson(), Gamma()) string \"cox\" survival data (default: gaussian()). censoring_rate Numeric [0,1]; fraction censored Cox models (default: 0.3). baseline_hazard Numeric function; constant hazard rate Cox, hazard function provided (default: 1).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/generate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Synthetic Data for Benchmark Simulations — generate","text":"list components: X n × p design matrix specified correlation. y Response: Numeric vector length n (GLMs). n × 2 matrix (time, status) (Cox). eta Linear predictor intercept + X %*% theta.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/generate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Synthetic Data for Benchmark Simulations — generate","text":"","code":"if (FALSE) { # \\dontrun{ # Gaussian data, p = 2 dat1 <- generate(n = 100, theta = c(1, 0), settings = \"ex1\",                  family = gaussian(), dispersion = 2)  # Binomial data with probit link dat2 <- generate(n = 200, theta = c(0.5, -0.5),                  family = binomial(link = \"probit\"),                  settings = \"ex2\", rho = 0.7)  # Cox survival data dat3 <- generate(n = 150, theta = c(1, 1, 0),                  settings = \"ex3\", family = \"cox\",                  censoring_rate = 0.2, baseline_hazard = 0.05) } # }"},{"path":"https://yizenglistat.github.io/glmcs/reference/glmcs-package.html","id":null,"dir":"Reference","previous_headings":"","what":"glmcs: Generalized Linear Models with Confident Sets — glmcs-package","title":"glmcs: Generalized Linear Models with Confident Sets — glmcs-package","text":"Implements likelihood-based additive single-effect regression (LASER) via blockwise coordinate ascent algorithm, providing confident sets variable selection uncertainty quantification. Features include robust variable selection high multicollinearity, confident sets capture posterior uncertainty variable inclusion, flexible modeling linear, generalized linear, Cox regression, high performance via C++ backend, configurable parameters number effects, coverage, convergence tolerance.","code":""},{"path":[]},{"path":"https://yizenglistat.github.io/glmcs/reference/glmcs-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"glmcs: Generalized Linear Models with Confident Sets — glmcs-package","text":"Maintainer: Yizeng Li yizenglistat@gmail.com Authors: Wei Pan panxx014@umn.edu","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Linear Models with Confidence Sets (GLMCS) — glmcs","title":"Generalized Linear Models with Confidence Sets (GLMCS) — glmcs","text":"Fits sparse Likelihood-based Additive Single-Effect Regression (LASER) model using iteratively blockwise coordinate ascent. model represents coefficient vector sum sparse \"single effects\" produces confidence sets variable selection based posterior model probabilities.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Linear Models with Confidence Sets (GLMCS) — glmcs","text":"","code":"glmcs(   X,   y,   L = 10L,   family = gaussian(),   coverage = 0.95,   cor_threshold = 0.5,   standardize = TRUE,   null_threshold = 1e-05,   tol = 0.05,   lambda = 0,   tau = 1e-05,   ties = c(\"efron\", \"breslow\"),   max_iter = 500L,   seed = NULL )"},{"path":"https://yizenglistat.github.io/glmcs/reference/glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Linear Models with Confidence Sets (GLMCS) — glmcs","text":"X Numeric matrix predictors (n × p). vector provided, converted single-column matrix. y Response variable: GLMs: numeric vector length n Cox models: numeric matrix 2 columns (time, status) n rows L Integer specifying number components fit (default: 10). truncated min(10, ncol(X)) necessary. family family object specifying model type (e.g., gaussian(), binomial(), poisson(), Gamma()) list(family=\"cox\") Cox regression. coverage Numeric \\([0,1]\\) specifying target coverage probability confidence sets (default: 0.95). cor_threshold Numeric \\([0,1]\\) specifying minimum absolute correlation required variables grouped confidence set (default: 0.5). standardize Logical indicating whether center scale predictors fitting (default: TRUE). null_threshold Numeric specifying threshold coefficients set zero (default: 1e-5). tol Numeric specifying convergence tolerance expected log-likelihood iterations (default: 5e-2). lambda Numeric penalty weight truncated-L1 penalty (default: 0.0). 0, penalization applied. tau Numeric truncation parameter truncated-L1 penalty (default: 1e-5). Controls transition L1 L0 regularization. ties Character string specifying method handling tied event times Cox regression: \"efron\" (default) \"breslow\". max_iter Integer specifying maximum number coordinate ascent iterations (default: 100). seed Integer seed reproducibility (default: NULL).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Linear Models with Confidence Sets (GLMCS) — glmcs","text":"list class \"glmcs\" containing: call matched call X model matrix y response vector/matrix family family object used theta p × L matrix estimated coefficients single effect intercept Estimated intercept (NULL Cox regression) pmp p × L matrix posterior model probabilities dispersion Estimated dispersion parameter loglik p × L matrix log-likelihoods bic p × L matrix BIC values bic_diff p × L matrix BIC differences null model bf p × L matrix Bayes factors marginal Vector marginal inclusion probabilities predictor kept Logical vector indicating effects retained cs List confidence sets based posterior probabilities niter Number iterations performed max_iter Number maximum iterations elapsed Elapsed computation time seconds","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/glmcs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Linear Models with Confidence Sets (GLMCS) — glmcs","text":"LASER model decomposes coefficient vector sum L sparse components. iteration, algorithm cyclically updates one component holding others fixed. component, fits univariate model predictor, computes model probabilities (via BIC), updates coefficients probability-weighted averages. approach extends traditional GLMs providing Bayesian-inspired confidence sets variable selection. Supported model families include: Gaussian linear regression Binomial logistic regression Poisson regression Gamma regression GLM family regression Cox proportional hazards regression","code":""},{"path":[]},{"path":"https://yizenglistat.github.io/glmcs/reference/glmcs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Linear Models with Confidence Sets (GLMCS) — glmcs","text":"","code":"if (FALSE) { # \\dontrun{ # Gaussian linear regression example set.seed(42) n <- 100 p <- 50 X <- matrix(rnorm(n*p), n, p) colnames(X) <- paste0(\"X\", 1:p) true_beta <- c(rep(1, 5), rep(0, p-5)) y <- X %*% true_beta + rnorm(n)  # Fit model with 3 components fit <- glmcs(X, y, L = 3, family = gaussian())  # Examine results summary(fit) plot(fit)  # Extract coefficients coef(fit) coef(fit, intercept = TRUE)  # Cox regression example X <- matrix(rnorm(100*10), 100, 10) colnames(X) <- paste0(\"X\", 1:10) times <- rexp(100, rate = exp(0.5 * X[,1] + 0.5 * X[,2])) status <- rbinom(100, 1, 0.7) y_cox <- cbind(times, status)  fit_cox <- glmcs(X, y_cox, L = 2, family = list(family = \"cox\")) summary(fit_cox) } # }"},{"path":"https://yizenglistat.github.io/glmcs/reference/is_covered.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","title":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","text":"Determines true active variables included least one provided confidence sets. Returns TRUE every element true_active appears union sets, FALSE otherwise.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/is_covered.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","text":"","code":"is_covered(confidence_sets, true_active)"},{"path":"https://yizenglistat.github.io/glmcs/reference/is_covered.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","text":"confidence_sets list integer vectors, representing confidence set selected variable indices. single vector provided, coerced list length one. true_active Integer vector true active variable indices.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/is_covered.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","text":"Logical scalar. TRUE elements true_active contained union confidence_sets, FALSE otherwise.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/is_covered.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Whether True Actives Are Covered by Confidence Sets — is_covered","text":"","code":"# Single set, true actives 1 and 3 are both covered is_covered(confidence_sets = c(1, 3, 5), true_active = c(1, 3)) #> [1] TRUE  # Multiple sets, true active 2 appears in one of them sets <- list(cs1 = c(1,4), cs2 = c(2,5), cs3 = c(3)) is_covered(confidence_sets = sets, true_active = c(2,3)) #> [1] TRUE  # Not covered if any true active is missing is_covered(confidence_sets = list(c(1,4)), true_active = c(1,2)) #> [1] FALSE"},{"path":"https://yizenglistat.github.io/glmcs/reference/iskept.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine Non‑Uniform Columns via Distance Measures — iskept","title":"Determine Non‑Uniform Columns via Distance Measures — iskept","text":"Identifies columns probability matrix deviate uniform distribution computing chosen distance metric splitting distances two clusters.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/iskept.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine Non‑Uniform Columns via Distance Measures — iskept","text":"prob_mat Numeric \\(n \\times m\\) matrix probabilities (column sums  1). method Character; one \"tv\", \"js\", \"hellinger\", \"l2\", \"chi2\", \"kl\", \"kolmogorov\", \"wasserstein\".","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/iskept.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine Non‑Uniform Columns via Distance Measures — iskept","text":"Logical vector length \\(m\\), TRUE indicates column deemed non‑uniform.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/iskept.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Determine Non‑Uniform Columns via Distance Measures — iskept","text":"Given probability matrix prob_mat dimension \\(n \\times m\\) whose columns sum  1, function computes, column \\(j\\), distance \\(d_j\\) prob_mat[, j] uniform distribution \\(u = (1/n, \\dots, 1/n)\\).  Supported metrics total variation, Jensen–Shannon divergence, Hellinger distance, L2 distance, Chi‑squared, Kullback–Leibler divergence, Kolmogorov–Smirnov statistic, 1st‑Wasserstein distance.  distances \\(\\{d_1,\\dots,d_m\\}\\) clustered via \\(k=2\\) k‑means cluster larger mean marked “non‑uniform.”  clustering fails, maximum‑gap threshold sorted distances used instead.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/iskept.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine Non‑Uniform Columns via Distance Measures — iskept","text":"","code":"# A 5×3 probability matrix P <- matrix(c(   0.2, 0.33, 0.10,   0.2, 0.33, 0.20,   0.2, 0.33, 0.30,   0.2, 0.01, 0.30,   0.2, 0.00, 0.10 ), nrow = 5, byrow = TRUE) iskept(P, method = \"js\") #> [1] FALSE  TRUE FALSE"},{"path":"https://yizenglistat.github.io/glmcs/reference/logLik.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Log-Likelihood from a glmcs Object — logLik.glmcs","title":"Extract Log-Likelihood from a glmcs Object — logLik.glmcs","text":"Returns log-likelihood glmcs model object.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/logLik.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Log-Likelihood from a glmcs Object — logLik.glmcs","text":"","code":"# S3 method for class 'glmcs' logLik(object, ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/logLik.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Log-Likelihood from a glmcs Object — logLik.glmcs","text":"object fitted model object class \"glmcs\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/logLik.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Log-Likelihood from a glmcs Object — logLik.glmcs","text":"Log-likelihood value.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/plot.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a glmcs Model Object — plot.glmcs","title":"Plot a glmcs Model Object — plot.glmcs","text":"Produces various plots visualizing glmcs model results.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/plot.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a glmcs Model Object — plot.glmcs","text":"","code":"# S3 method for class 'glmcs' plot(x, which = c(\"coefficients\", \"probabilities\", \"sets\"), n_top = 20, ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/plot.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a glmcs Model Object — plot.glmcs","text":"x glmcs object. Integer character string specifying plot create: 1 \"coefficients\": Plot coefficient estimates 2 \"probabilities\": Plot inclusion probabilities 3 \"sets\": Visualization confidence sets n_top Integer specifying many top coefficients display. ... Additional arguments passed plotting functions.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/plot.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a glmcs Model Object — plot.glmcs","text":"ggplot2 object.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/plot_cs_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot inclusion probabilities for a set of ","title":"Plot inclusion probabilities for a set of ","text":"Plot inclusion probabilities set \"confidence sets\"","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/plot_cs_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot inclusion probabilities for a set of ","text":"","code":"plot_cs_matrix(   prob_mat,   row_labels = paste0(\"CS\", seq_len(nrow(prob_mat))),   var_labels = seq_len(ncol(prob_mat)),   low_col = \"white\",   high_col = \"black\",   drop_zero = TRUE )"},{"path":"https://yizenglistat.github.io/glmcs/reference/plot_cs_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot inclusion probabilities for a set of ","text":"prob_mat Numeric matrix (r × p) probabilities (row sums 1). row_labels Optional character vector length r. Default paste0(\"CS\", 1:r). var_labels Optional character numeric vector length p. Default 1:p. low_col Colour P≈0. Default \"white\". high_col Colour P≈1. Default \"black\". drop_zero Logical; TRUE, drop zero-probability entries (default: TRUE).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/plot_cs_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot inclusion probabilities for a set of ","text":"ggplot2 object showing crosses size ∝ P colour ∝ P.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/predict.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Predictions from a glmcs Object — predict.glmcs","title":"Model Predictions from a glmcs Object — predict.glmcs","text":"Produces predictions glmcs model new data original training data.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/predict.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Predictions from a glmcs Object — predict.glmcs","text":"","code":"# S3 method for class 'glmcs' predict(object, newdata = NULL, type = c(\"link\", \"response\", \"terms\"), ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/predict.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Predictions from a glmcs Object — predict.glmcs","text":"object fitted model object class \"glmcs\". newdata optional data frame matrix look variables predict. omitted, fitted values returned. type Character string specifying type prediction: \"link\": predictions scale linear predictors \"response\": predictions scale response \"terms\": contributions individual terms ... Additional arguments passed family's link function.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/predict.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Predictions from a glmcs Object — predict.glmcs","text":"Vector matrix predictions, depending type.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/print.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a glmcs Model Object — print.glmcs","title":"Print a glmcs Model Object — print.glmcs","text":"Print glmcs Model Object","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/print.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a glmcs Model Object — print.glmcs","text":"","code":"# S3 method for class 'glmcs' print(x, ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/print.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a glmcs Model Object — print.glmcs","text":"x glmcs object. ... Additional arguments passed print.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/print.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a glmcs Model Object — print.glmcs","text":"object invisibly.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/print.summary.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a glmcs Model Summary — print.summary.glmcs","title":"Print a glmcs Model Summary — print.summary.glmcs","text":"Print glmcs Model Summary","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/print.summary.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a glmcs Model Summary — print.summary.glmcs","text":"","code":"# S3 method for class 'summary.glmcs' print(x, digits = max(3, getOption(\"digits\") - 3), max_sets = 5, ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/print.summary.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a glmcs Model Summary — print.summary.glmcs","text":"x summary.glmcs object created summary.glmcs(). digits Number significant digits use printing. max_sets Maximum number confidence sets display (default: 5). ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/print.summary.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a glmcs Model Summary — print.summary.glmcs","text":"summary object invisibly.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/residuals.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Residuals from a glmcs Object — residuals.glmcs","title":"Extract Residuals from a glmcs Object — residuals.glmcs","text":"Extracts residuals glmcs model fit.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/residuals.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Residuals from a glmcs Object — residuals.glmcs","text":"","code":"# S3 method for class 'glmcs' residuals(object, type = c(\"deviance\", \"pearson\", \"response\", \"working\"), ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/residuals.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Residuals from a glmcs Object — residuals.glmcs","text":"object fitted model object class \"glmcs\". type Character string indicating type residuals returned: \"deviance\": deviance residuals \"pearson\": Pearson residuals \"response\": response residuals (observed - fitted) \"working\": working residuals ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/residuals.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Residuals from a glmcs Object — residuals.glmcs","text":"numeric vector residuals.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/single_effect_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Single‐Effect Fit for GLM or Cox with Optional Truncated‐L1 Penalty — single_effect_fit","title":"Compute Single‐Effect Fit for GLM or Cox with Optional Truncated‐L1 Penalty — single_effect_fit","text":"Applies single‐effect model column predictor matrix using either GLM (via IRLS + truncated‐L1) Cox partial likelihood (via penalized IRLS).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/single_effect_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Single‐Effect Fit for GLM or Cox with Optional Truncated‐L1 Penalty — single_effect_fit","text":"X Numeric matrix (n × p) predictors. column fit separately. y Response: GLMs: numeric vector length n. Cox: numeric matrix 2 columns (time, status) n rows. family stats::family object (e.g. gaussian(), binomial(), poisson()) Cox family list family = \"cox\". offset Numeric scalar vector (length n) giving linear predictor offset (default: 0). standardize Logical: TRUE, center scale predictor column fitting (default: TRUE). ties Character: ties method Cox partial likelihood (\"efron\" \"breslow\", default: \"efron\"). lambda Numeric penalty weight; ≤ 0, defaults \\(\\sqrt{2\\log(n)/n}\\) (default: 0.0). tau Numeric truncation parameter; ≤ 0, defaults 1.0 (default: 1.0). null_threshold Numeric threshold estimated coefficient set zero (default: 1e-6).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/single_effect_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Single‐Effect Fit for GLM or Cox with Optional Truncated‐L1 Penalty — single_effect_fit","text":"list length p, element list components: theta Estimated coefficient predictor. loglik Unpenalized log‐likelihood fitted coefficient. bic Bayesian Information Criterion: \\(-2*logLik + 2\\log(n)\\).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/single_effect_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Single‐Effect Fit for GLM or Cox with Optional Truncated‐L1 Penalty — single_effect_fit","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) n <- 80; p <- 3 X <- matrix(rnorm(n*p), n, p) # Gaussian example y_gauss <- X[,1] * 1.2 + rnorm(n) res_glm <- single_effect_fit(X, y_gauss, family = gaussian())  # Cox example times <- rexp(n, rate = exp(0.5 * X[,2])) status <- rbinom(n, 1, 0.7) y_cox <- cbind(time=times, status=status) res_cox <- single_effect_fit(X, y_cox, family = list(family=\"cox\")) } # }"},{"path":"https://yizenglistat.github.io/glmcs/reference/summarize_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize Coefficient Estimates Across Simulations — summarize_coef","title":"Summarize Coefficient Estimates Across Simulations — summarize_coef","text":"Given matrix simulated coefficient estimates true coefficient vector, compute per‐variable summary statistics: empirical mean standard deviation estimates, alongside true value.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/summarize_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize Coefficient Estimates Across Simulations — summarize_coef","text":"","code":"summarize_coef(sims_coef, true_theta, decimal = 2)"},{"path":"https://yizenglistat.github.io/glmcs/reference/summarize_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize Coefficient Estimates Across Simulations — summarize_coef","text":"sims_coef Numeric matrix dimension \\(p \\times n_{\\text{sim}}\\), row corresponds one predictor column simulation replicate. true_theta Numeric vector length \\(p\\), containing true coefficient values predictor. decimal Nonnegative integer.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/summarize_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize Coefficient Estimates Across Simulations — summarize_coef","text":"data.frame columns: true true coefficient values, true_theta. mean Row‐wise mean sims_coef, average estimated coefficient. ssd Row‐wise standard deviation sims_coef, empirical sampling variability.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/summarize_coef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize Coefficient Estimates Across Simulations — summarize_coef","text":"","code":"# Suppose we ran 100 simulations for 3 predictors set.seed(42) true_theta <- c(1.5, 0, -2) sims_coef  <- matrix(rnorm(3 * 100, mean = rep(true_theta, each = 100), sd = 0.3),                      nrow = 3, byrow = TRUE) summarize_coef(sims_coef, true_theta) #>   true  mean  ssd #> 1  1.5  1.51 0.31 #> 2  0.0 -0.03 0.27 #> 3 -2.0 -2.00 0.31"},{"path":"https://yizenglistat.github.io/glmcs/reference/summarize_cs.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize Multi‐Set Confidence Regions Across Simulations — summarize_cs","title":"Summarize Multi‐Set Confidence Regions Across Simulations — summarize_cs","text":"Given list simulation results run may return multiple confidence sets (e.g. cs1, cs2, …), function enumerates distinct patterns sets, counts often occurs, computes fraction simulations, tests whether union sets pattern covers true active variables.  Within pattern, individual sets ordered first size (smallest first), lexicographically indices.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/summarize_cs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize Multi‐Set Confidence Regions Across Simulations — summarize_cs","text":"","code":"summarize_cs(cs_list, true_active, decimal = 2)"},{"path":"https://yizenglistat.github.io/glmcs/reference/summarize_cs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize Multi‐Set Confidence Regions Across Simulations — summarize_cs","text":"cs_list List length n_sims. element either: R list (e.g. list(cs1=..., cs2=..., …)) integer vectors, NULL empty list, meaning confidence sets returned. inner integer vector holds indices single confidence set. true_active Integer vector true active variable indices. decimal Nonnegative integer.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/summarize_cs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize Multi‐Set Confidence Regions Across Simulations — summarize_cs","text":"data.frame columns: set Character: unique simulation pattern rendered comma‐separated set literals, e.g.\\  \"{1,4}, {2,3}\".  empty pattern shown \"{}\". count Integer: number simulations produced exactly pattern sets. percent Numeric: count divided n_sims. cover Logical: TRUE union sets pattern contains every element true_active. Rows sorted descending order count.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/summary.glmcs.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize a glmcs Model Fit — summary.glmcs","title":"Summarize a glmcs Model Fit — summary.glmcs","text":"Produces summary glmcs model fit, including coefficients, confidence sets, model fit statistics.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/summary.glmcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize a glmcs Model Fit — summary.glmcs","text":"","code":"# S3 method for class 'glmcs' summary(object, ...)"},{"path":"https://yizenglistat.github.io/glmcs/reference/summary.glmcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize a glmcs Model Fit — summary.glmcs","text":"object fitted model object class \"glmcs\". ... Additional arguments (used).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/summary.glmcs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize a glmcs Model Fit — summary.glmcs","text":"list class \"summary.glmcs\" containing various summary statistics.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Univariate Fit with Optional Truncated‐L1 Penalty — univariate_fit","title":"Compute Univariate Fit with Optional Truncated‐L1 Penalty — univariate_fit","text":"Fits single‐covariate model (GLM Cox) optional standardization truncated‐L1 penalty coefficient.  GLMs uses IRLS capped‐L1 update; Cox uses penalized IRLS partial likelihood.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Univariate Fit with Optional Truncated‐L1 Penalty — univariate_fit","text":"x Numeric vector covariate values (length n); scalar expands zeros. y Response: GLMs: numeric vector length n. Cox: numeric matrix 2 columns (time, status) n rows. family stats::family object (e.g. gaussian(), binomial(), poisson()) Cox family list family = \"cox\". offset Numeric scalar vector (length n) giving linear predictor offset (default: 0). standardize Logical: TRUE, center scale x fitting (default: TRUE). ties Character: ties method Cox partial likelihood (\"efron\" \"breslow\", default: \"efron\"). lambda Numeric penalty weight; NULL ≤ 0, defaults \\(\\sqrt{2\\log(n)/n}\\). tau Numeric truncation parameter; NULL ≤ 0, defaults 0.5. null_threshold Numeric threshold final theta set zero (default: 1e-6). max_iter Integer: maximum number IRLS iterations (default: 25). tol Numeric convergence tolerance theta updates (default: 1e-8).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Univariate Fit with Optional Truncated‐L1 Penalty — univariate_fit","text":"list elements: theta Estimated coefficient (undoing standardization). loglik Unpenalized log-likelihood estimated theta. bic Bayesian Information Criterion: \\(-2*loglik + 2\\log(n)\\).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Univariate Fit with Optional Truncated‐L1 Penalty — univariate_fit","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(101) n <- 50 x <- rnorm(n) # Gaussian GLM y_gauss <- 1.5*x + rnorm(n) res1 <- univariate_fit(x, y_gauss, family = gaussian(), offset = 0)  # Cox example times  <- rexp(n, rate = exp(0.7*x)) status <- rbinom(n, 1, 0.6) y_cox  <- cbind(time=times, status=status) res2 <- univariate_fit(x, y_cox, family = list(family=\"cox\")) } # }"},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_irls_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","title":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","text":"Fits univariate Cox proportional hazards model maximizing partial log-likelihood using Iteratively Reweighted Least Squares (IRLS) approach. Supports Breslow Efron approximations handling ties.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_irls_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","text":"x Numeric vector length n: covariate values. y Numeric matrix shape n × 2, : y[,1] observed time y[,2] event indicator (1 = event, 0 = censored) offset Numeric scalar vector length n. Optional offset linear predictor. ties Character string specifying method handle ties: \"breslow\" (default) \"efron\". lambda Numeric penalty weight; ≤0 defaults \\(\\sqrt{2\\log(n)/n}\\). tau Numeric truncation parameter; ≤0 uses grid {1/n,…,5/n} n≤500 1/n otherwise. max_iter Integer: maximum number IRLS iterations. Default 25. tol Numeric: convergence tolerance parameter change. Default 1e-8.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_irls_cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","text":"numeric scalar representing estimated regression coefficient theta.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_irls_cox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","text":"function starts initial coefficient value 0 updates slope estimate using Newton-Raphson iterations convergence reaching maximum number iterations. linear predictor lp = offset + theta * x. score function observed information used update estimate.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_irls_cox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Univariate Cox Model via Iteratively Reweighted Least Squares (IRLS) — univariate_irls_cox","text":"","code":"if (FALSE) { # \\dontrun{ x <- c(1, 2, 3, 4) y <- matrix(c(4,1, 1,1, 3,0, 2,1), ncol = 2, byrow = TRUE) univariate_irls_cox(x, y, offset = 0, ties = \"efron\", max_iter = 50, tol = 1e-6) } # }"},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_irls_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Truncated‐L1 IRLS Estimate for Univariate GLM — univariate_irls_glm","title":"Compute Truncated‐L1 IRLS Estimate for Univariate GLM — univariate_irls_glm","text":"Fits single‐covariate GLM using IRLS truncated‐L1 penalty. Solves: $$\\min_\\theta\\;-\\ell(\\theta) \\;+\\;\\lambda\\,\\min\\bigl(1,|\\theta|/\\tau\\bigr)$$ via iteratively reweighted least squares, closed‐form capped‐L1 update step.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_irls_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Truncated‐L1 IRLS Estimate for Univariate GLM — univariate_irls_glm","text":"x Numeric vector covariates (length n). y Numeric response vector (length n). family stats::family object (e.g. gaussian(), binomial(), poisson()). offset Numeric scalar vector (length n) giving linear predictor offset. lambda Numeric penalty weight; ≤0 defaults \\(\\sqrt{2\\log(n)/n}\\). tau Numeric truncation parameter; ≤0 uses grid {1/n,…,5/n} n≤500 1/n otherwise. max_iter Integer. Maximum number IRLS iterations. tol Numeric convergence tolerance θ.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_irls_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Truncated‐L1 IRLS Estimate for Univariate GLM — univariate_irls_glm","text":"Numeric scalar: estimated coefficient \\(\\hat\\theta\\).","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_irls_glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Truncated‐L1 IRLS Estimate for Univariate GLM — univariate_irls_glm","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(42) n <- 100 x <- rnorm(n) # Gaussian example y <- 2*x + rnorm(n) univariate_irls_glm(x, y, gaussian(), offset=0,                     lambda=0, tau=0, max_iter=25, tol=1e-8) } # }"},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_loglik.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Univariate Log-Likelihood for GLM or Cox Model — univariate_loglik","title":"Compute Univariate Log-Likelihood for GLM or Cox Model — univariate_loglik","text":"Calculates log-likelihood single covariate effect either generalized linear model (GLM) family Cox proportional hazards model.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_loglik.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Univariate Log-Likelihood for GLM or Cox Model — univariate_loglik","text":"x Numeric vector length n: covariate values. y GLMs: numeric vector length n; Cox: numeric matrix two columns (time, status) n rows. family GLM family object (e.g. gaussian(), binomial(), poisson()) Cox family list element family=\"cox\". theta Numeric scalar: coefficient evaluate log-likelihood. offset Numeric scalar vector length n: offset linear predictor. ties Character string: tie-handling method Cox partial likelihood; one \"efron\" \"breslow\".","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_loglik.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Univariate Log-Likelihood for GLM or Cox Model — univariate_loglik","text":"numeric scalar giving log-likelihood univariate fit.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_loglik.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Univariate Log-Likelihood for GLM or Cox Model — univariate_loglik","text":"","code":"if (FALSE) { # \\dontrun{ # Gaussian example x <- rnorm(100) y <- 2 * x + rnorm(100) univariate_loglik(x, y, family = gaussian(), theta = 2, offset = 0)  # Binomial example x <- rnorm(200) eta <- -1 + 1.5 * x p <- plogis(eta) y <- rbinom(200, 1, p) univariate_loglik(x, y, family = binomial(link = \"logit\"),                   theta = 1.5, offset = 0)  # Cox example x <- rnorm(50) times <- rexp(50) status <- rbinom(50, 1, 0.5) ymat <- cbind(times, status) univariate_loglik(x, ymat, family = list(family = \"cox\"),                   theta = 0.5, offset = 0, ties = \"efron\") } # }"},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_loglik_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","title":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","text":"Computes partial log-likelihood univariate Cox proportional hazards model. Handles ties using either Breslow Efron approximation.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_loglik_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","text":"x Numeric vector length n: covariate values individual. y Numeric matrix shape n × 2, : - y[,1] contains event/censoring times - y[,2] contains event status (1 = event, 0 = censored) theta Numeric scalar: coefficient evaluate log-likelihood . offset Numeric vector length n, scalar. Optional offset linear predictor. ties Character string: tie-handling method. Must either \"breslow\" \"efron\".","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_loglik_cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","text":"Numeric scalar: partial log-likelihood value.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_loglik_cox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","text":"function computes linear predictor : lp = offset + theta * x. partial log-likelihood calculated using either Breslow Efron method handling tied event times.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/univariate_loglik_cox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Log-Likelihood for Univariate Cox Model — univariate_loglik_cox","text":"","code":"if (FALSE) { # \\dontrun{ x <- c(1, 2, 3, 4) y <- matrix(c(4,1, 1,1, 3,0, 2,1), ncol = 2, byrow = TRUE) univariate_loglik_cox(x, y, offset = 0, theta = 0.5, ties = \"efron\") } # }"},{"path":"https://yizenglistat.github.io/glmcs/reference/update_dispersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Dispersion for GLM Family — update_dispersion","title":"Estimate Dispersion for GLM Family — update_dispersion","text":"Computes dispersion parameter Generalized Linear Model (GLM) using either Pearson residual method deviance-based approach.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/update_dispersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Dispersion for GLM Family — update_dispersion","text":"y Numeric response vector length n. family GLM family object (e.g., gaussian(), poisson(), Gamma()). offset Numeric vector scalar representing linear predictor eta; defaults 0. approach Character string: either \"pearson\" \"deviance\".","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/update_dispersion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Dispersion for GLM Family — update_dispersion","text":"numeric scalar representing estimated dispersion.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/update_dispersion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Dispersion for GLM Family — update_dispersion","text":"function supports family object stats::family(), gaussian(), poisson(), Gamma(), etc. linear predictor given offset, inverse link function applied compute mean response mu. approach = \"pearson\", computes: $$ \\phi = \\frac{1}{n - p} \\sum_i \\left( \\frac{y_i - \\mu_i}{\\sqrt{\\text{var}(\\mu_i)}} \\right)^2 $$ approach = \"deviance\", computes: $$ \\phi = \\frac{1}{n - p} \\sum_i \\text{dev}_i $$ dev_i deviance residuals.","code":""},{"path":"https://yizenglistat.github.io/glmcs/reference/update_dispersion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Dispersion for GLM Family — update_dispersion","text":"","code":"if (FALSE) { # \\dontrun{ y <- rgamma(100, shape = 2, rate = 2) offset <- rep(log(mean(y)), 100) update_dispersion(y, Gamma(), offset = offset, approach = \"pearson\") } # }"}]
