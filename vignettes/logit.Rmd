---
title: "Logistic Regression with Correlated Predictors"
author: "Yizeng Li"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
    fig_width: 5
    fig_height: 4
tags:
  - "binary regression"
  - "logistic"
  - "correlated predictors"
vignette: >
  %\VignetteIndexEntry{Logistic Regression with Correlated Predictors}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse   = TRUE,
  comment    = "##",
  echo       = TRUE,
  message    = FALSE,
  warning    = FALSE,
  fig.align  = "center",
  dpi        = 120
)
library(ggplot2)
```

# Introduction

The **glmsusie** package implements the generalized sum of single effects (gSuSiE) model, which represents the overall effect as a sum of a small number of *single-effect* components. This approach extends the [SuSiE method](https://stephenslab.github.io/susieR/index.html) to general regression models including logistic regression.

In this vignette, we demonstrate gSuSiE's performance with binary outcomes and highly correlated predictors:

- Simulate a block-wise correlation structure with 100 predictors
- Apply gSuSiE to perform variable selection via `glmsusie()` with binomial family
- Visualize coefficient estimates, posterior inclusion probabilities (PIPs), and credible sets (CSs)
- Evaluate predictive performance for binary classification

# Simulate data

We generate $n=2500$ observations and $p=100$ predictors with block-wise correlation. Every 10 consecutive variables are highly correlated ($\rho=0.95$) within each block, while blocks are independent. Only 4 variables have nonzero effects, located in different correlation blocks.

```{r simulate}
set.seed(42)
n <- 2500     # sample size
p <- 100      # number of predictors
L <- 10       # number of single-effect components
block_size <- 10
n_blocks <- p / block_size
rho <- 0.95    # within-block correlation

# Create block-wise correlation matrix
Sigma <- matrix(0, p, p)
for (b in 1:n_blocks) {
  block_idx <- ((b-1)*block_size + 1):(b*block_size)
  # Within-block correlation matrix
  block_corr <- matrix(rho, block_size, block_size)
  diag(block_corr) <- 1
  Sigma[block_idx, block_idx] <- block_corr
}

# Generate correlated predictors
X <- MASS::mvrnorm(n, mu = rep(0, p), Sigma = Sigma)

# True sparse coefficients (one per block, spread across different blocks)
theta_true <- rep(0, p)
theta_true[c(3, 18, 47, 82)] <- c(1, -1, 1, -1)

# Generate binary response via logistic model
linear_pred <- drop(-3 + X %*% theta_true) # with intercept
prob <- plogis(linear_pred)  # inverse logit
y <- rbinom(n, 1, prob)

cat("True nonzero coefficients at positions:", which(theta_true != 0), "\n")
cat("True coefficient values:", theta_true[theta_true != 0], "\n")
cat("Response proportion (positives):", mean(y), "\n")
```

# Fit gSuSiE model

We allow up to $L=10$ single effects and use the binomial family for logistic regression. The method is robust to larger $L$ values with minimal overfitting risk.

```{r fit}
# Load glmsusie library
library(glmsusie)

# Model fitting
fit <- glmsusie(
  X      = X,
  y      = y,
  L      = L,
  family = binomial()
)

summary(fit)
```

# Results

## Coefficient estimates

The method successfully identifies the true signal locations despite high correlation within blocks:

```{r coef}
plot(fit, which = "coefficients")
```

## Posterior inclusion probabilities

Shows the probability that each variable is included in any single-effect component:

```{r prob}
plot(fit, which = "probabilities")
```

## 95% credible sets

Each credible set contains variables where at least one is likely active with 95% confidence. Note how the method handles correlated variables within blocks:

```{r cs}
plot(fit, which = "sets")
```

## Credible sets summary
```{r cs_summary}
# Summary of credible sets
cs_sets <- fit$cs$sets
if (length(cs_sets) > 0) {
  cat("Number of credible sets:", length(cs_sets), "\n")
  for (i in seq_along(cs_sets)) {
    cat("CS", i, "contains variables:", cs_sets[[i]], "\n")
  }
  
  # Check coverage of true variables
  true_vars <- which(theta_true != 0)
  covered_vars <- intersect(unlist(cs_sets), true_vars)
  cat("\nTrue variables covered by credible sets:", covered_vars, "\n")
} else {
  cat("No credible sets identified\n")
}
```

## Coefficient comparison

Compare estimated coefficients with true values:

```{r coef_comparison}
# Extract coefficients
coef_est <- coef(fit)
comparison <- data.frame(
  Variable = 1:p,
  True_Coef = theta_true,
  Estimated_Coef = coef_est,
  PIP = fit$pip
)

# Show results for true active variables
active_comparison <- comparison[theta_true != 0, ]
print(active_comparison)
```

# Conclusion

This example demonstrates that gSuSiE effectively handles logistic regression with highly correlated predictors. The method identifies relevant variables even when they are embedded within correlation blocks, providing both point estimates and uncertainty quantification through credible sets. The binomial family implementation successfully recovers the sparse signal structure in binary outcomes.